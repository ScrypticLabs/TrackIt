{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS NOTEBOOK TRAINS THE RNN LSTM MANY-TO-MANY MODEL WHERE PAST=10 frames AND FUTURE=90 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from data_loader import DataLoader\n",
    "from utils.visualize import show_images_in_grid, show_images_as_video, show_reconstructions, compare_images_as_video\n",
    "from cnn import Autoencoder\n",
    "from utils.build_futures import *\n",
    "from rnn_many_to_many import Seq2Seq\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_data_loader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_data_loader.X_train = np.load(root+\"/../datasets/train/32/X_train_normalized.npy\")\n",
    "rnn_data_loader.X_val = np.load(root+\"/../datasets/val/32/X_val_normalized.npy\")\n",
    "rnn_data_loader.X_test = np.load(root+\"/../datasets/test/32/X_test_normalized.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LET'S COMPUTE THE EMBEDDINGS FROM THE DATA AND TRAINED AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abhi/anaconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "ae = Autoencoder()\n",
    "ae.build_model(input_dim=(32, 32, 3), latent_dim=(64,))\n",
    "ae.set_weights(root+\"/../models/autoencoder_32.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ae.encode_series(rnn_data_loader.X_train)\n",
    "X_val = ae.encode_series(rnn_data_loader.X_val)\n",
    "X_test = ae.encode_series(rnn_data_loader.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 100, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = Seq2Seq()\n",
    "seq.build_model(input_length=20, input_dim=64, latent_dim=(256,), output_length=80, output_dim=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq.set_weights(root+\"/../models/seq2seq_many_to_many_recent_past_future_32.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 20, 1024)          4460544   \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 20, 512)           3147776   \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 256)               787456    \n",
      "_________________________________________________________________\n",
      "repeat_vector_3 (RepeatVecto (None, 80, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 80, 512)           1574912   \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 80, 1024)          6295552   \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 80, 64)            65600     \n",
      "=================================================================\n",
      "Total params: 16,331,840\n",
      "Trainable params: 16,331,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    \"loss\" : [],\n",
    "    \"val_loss\" : []\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 501\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 106.9601 - val_loss: 1101.9988\n",
      "EPOCH 502\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 105.2080 - val_loss: 1103.4888\n",
      "EPOCH 503\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 104.2407 - val_loss: 1106.7452\n",
      "EPOCH 504\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 104.1135 - val_loss: 1102.6273\n",
      "EPOCH 505\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 102.7079 - val_loss: 1103.4150\n",
      "EPOCH 506\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 103.3795 - val_loss: 1106.8813\n",
      "EPOCH 507\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 107.8564 - val_loss: 1105.7916\n",
      "EPOCH 508\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 114.0119 - val_loss: 1107.3146\n",
      "EPOCH 509\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 112.7672 - val_loss: 1106.8704\n",
      "EPOCH 510\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 115.9477 - val_loss: 1103.0316\n",
      "EPOCH 511\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 118.0992 - val_loss: 1100.6056\n",
      "EPOCH 512\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 125.4162 - val_loss: 1105.1990\n",
      "EPOCH 513\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 122.1362 - val_loss: 1113.5281\n",
      "EPOCH 514\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 120.4972 - val_loss: 1101.3650\n",
      "EPOCH 515\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 119.5478 - val_loss: 1101.6403\n",
      "EPOCH 516\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 120.9137 - val_loss: 1098.9489\n",
      "EPOCH 517\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 113.4057 - val_loss: 1103.4221\n",
      "EPOCH 518\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 114.7712 - val_loss: 1101.1539\n",
      "EPOCH 519\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 109.6278 - val_loss: 1102.5736\n",
      "EPOCH 520\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 104.8152 - val_loss: 1102.9999\n",
      "EPOCH 521\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 103.3334 - val_loss: 1112.0691\n",
      "EPOCH 522\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 103.1231 - val_loss: 1104.6116\n",
      "EPOCH 523\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.6831 - val_loss: 1106.0503\n",
      "EPOCH 524\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 99.1586 - val_loss: 1106.0649\n",
      "EPOCH 525\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 98.9210 - val_loss: 1107.6213\n",
      "EPOCH 526\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 99.2575 - val_loss: 1108.9279\n",
      "EPOCH 527\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 103.0518 - val_loss: 1106.0088\n",
      "EPOCH 528\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 105.6140 - val_loss: 1110.6743\n",
      "EPOCH 529\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 106.0072 - val_loss: 1105.7499\n",
      "EPOCH 530\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 108.0209 - val_loss: 1107.7059\n",
      "EPOCH 531\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 109.2238 - val_loss: 1112.8284\n",
      "EPOCH 532\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 115.9002 - val_loss: 1107.8051\n",
      "EPOCH 533\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 122.5882 - val_loss: 1103.5594\n",
      "EPOCH 534\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 121.9197 - val_loss: 1108.6393\n",
      "EPOCH 535\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 119.5831 - val_loss: 1099.4832\n",
      "EPOCH 536\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 122.5636 - val_loss: 1107.1304\n",
      "EPOCH 537\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 125.5420 - val_loss: 1106.0673\n",
      "EPOCH 538\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 131.8328 - val_loss: 1100.8237\n",
      "EPOCH 539\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 129.7640 - val_loss: 1107.0200\n",
      "EPOCH 540\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 129.8395 - val_loss: 1108.7178\n",
      "EPOCH 541\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 131.6840 - val_loss: 1093.0719\n",
      "EPOCH 542\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 138.8091 - val_loss: 1095.4913\n",
      "EPOCH 543\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 136.4642 - val_loss: 1094.6110\n",
      "EPOCH 544\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 129.5326 - val_loss: 1097.0251\n",
      "EPOCH 545\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 134.1887 - val_loss: 1099.1498\n",
      "EPOCH 546\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 129.3186 - val_loss: 1102.4542\n",
      "EPOCH 547\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 130.9724 - val_loss: 1104.9840\n",
      "EPOCH 548\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 146.7319 - val_loss: 1114.5748\n",
      "EPOCH 549\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 146.8710 - val_loss: 1112.1915\n",
      "EPOCH 550\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 136.4706 - val_loss: 1096.2909\n",
      "EPOCH 551\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 141.8459 - val_loss: 1113.9268\n",
      "EPOCH 552\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 145.5433 - val_loss: 1098.7216\n",
      "EPOCH 553\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 129.9299 - val_loss: 1096.5054\n",
      "EPOCH 554\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 123.2197 - val_loss: 1100.8916\n",
      "EPOCH 555\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 117.4950 - val_loss: 1094.4598\n",
      "EPOCH 556\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 114.5413 - val_loss: 1100.9872\n",
      "EPOCH 557\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 117.7249 - val_loss: 1100.4830\n",
      "EPOCH 558\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 109.4798 - val_loss: 1092.0675\n",
      "EPOCH 559\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 108.6509 - val_loss: 1095.4463\n",
      "EPOCH 560\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 109.6010 - val_loss: 1090.8916\n",
      "EPOCH 561\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 109.1740 - val_loss: 1103.1743\n",
      "EPOCH 562\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 110.1069 - val_loss: 1090.4027\n",
      "EPOCH 563\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 117.5203 - val_loss: 1096.1906\n",
      "EPOCH 564\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 110.5836 - val_loss: 1104.2468\n",
      "EPOCH 565\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 114.2575 - val_loss: 1107.2445\n",
      "EPOCH 566\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 112.9914 - val_loss: 1104.6392\n",
      "EPOCH 567\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 117.0543 - val_loss: 1104.2223\n",
      "EPOCH 568\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 131.0519 - val_loss: 1101.1709\n",
      "EPOCH 569\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 127.9720 - val_loss: 1093.4303\n",
      "EPOCH 570\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 134.5440 - val_loss: 1107.8628\n",
      "EPOCH 571\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 131.0159 - val_loss: 1092.2914\n",
      "EPOCH 572\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 145.6124 - val_loss: 1094.6959\n",
      "EPOCH 573\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 136.5691 - val_loss: 1109.3594\n",
      "EPOCH 574\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 139.8792 - val_loss: 1089.5513\n",
      "EPOCH 575\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 151.9795 - val_loss: 1094.4944\n",
      "EPOCH 576\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 145.7446 - val_loss: 1099.4828\n",
      "EPOCH 577\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 129.2540 - val_loss: 1098.9521\n",
      "EPOCH 578\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 129.7248 - val_loss: 1106.5677\n",
      "EPOCH 579\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 138.7480 - val_loss: 1099.8624\n",
      "EPOCH 580\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 133.4310 - val_loss: 1095.0597\n",
      "EPOCH 581\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 128.6019 - val_loss: 1094.7098\n",
      "EPOCH 582\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 122.1060 - val_loss: 1100.4307\n",
      "EPOCH 583\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 129.2996 - val_loss: 1110.9481\n",
      "EPOCH 584\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 125.4729 - val_loss: 1113.7261\n",
      "EPOCH 585\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 121.3306 - val_loss: 1097.6097\n",
      "EPOCH 586\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 118.5385 - val_loss: 1095.2809\n",
      "EPOCH 587\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 128.0951 - val_loss: 1105.3940\n",
      "EPOCH 588\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 124.3053 - val_loss: 1103.1927\n",
      "EPOCH 589\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 114.8954 - val_loss: 1108.7699\n",
      "EPOCH 590\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 111.2265 - val_loss: 1104.9471\n",
      "EPOCH 591\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 110.2605 - val_loss: 1094.9313\n",
      "EPOCH 592\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 104.8598 - val_loss: 1104.3439\n",
      "EPOCH 593\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.8602 - val_loss: 1109.0618\n",
      "EPOCH 594\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.6591 - val_loss: 1108.3185\n",
      "EPOCH 595\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.6536 - val_loss: 1104.5046\n",
      "EPOCH 596\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.8046 - val_loss: 1101.3225\n",
      "EPOCH 597\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.7184 - val_loss: 1103.7970\n",
      "EPOCH 598\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.4963 - val_loss: 1108.4148\n",
      "EPOCH 599\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 102.0590 - val_loss: 1106.1451\n",
      "EPOCH 600\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 103.0168 - val_loss: 1103.4993\n",
      "EPOCH 601\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.9385 - val_loss: 1111.0355\n",
      "EPOCH 602\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 107.0986 - val_loss: 1108.7175\n",
      "EPOCH 603\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 108.5432 - val_loss: 1105.4493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 604\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 117.3461 - val_loss: 1107.4097\n",
      "EPOCH 605\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 120.4705 - val_loss: 1113.0151\n",
      "EPOCH 606\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 120.3922 - val_loss: 1110.8224\n",
      "EPOCH 607\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 128.4806 - val_loss: 1109.9897\n",
      "EPOCH 608\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 135.5674 - val_loss: 1103.3988\n",
      "EPOCH 609\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 138.1260 - val_loss: 1114.8179\n",
      "EPOCH 610\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 127.7598 - val_loss: 1104.4641\n",
      "EPOCH 611\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 127.3065 - val_loss: 1107.1659\n",
      "EPOCH 612\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 143.8971 - val_loss: 1106.6489\n",
      "EPOCH 613\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 144.8949 - val_loss: 1102.0132\n",
      "EPOCH 614\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 131.0157 - val_loss: 1108.1655\n",
      "EPOCH 615\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 130.0202 - val_loss: 1104.3093\n",
      "EPOCH 616\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 133.6721 - val_loss: 1096.6927\n",
      "EPOCH 617\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 137.9477 - val_loss: 1103.9635\n",
      "EPOCH 618\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 125.2855 - val_loss: 1111.2778\n",
      "EPOCH 619\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 127.2813 - val_loss: 1105.8806\n",
      "EPOCH 620\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 143.6636 - val_loss: 1105.1801\n",
      "EPOCH 621\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 140.4418 - val_loss: 1101.6510\n",
      "EPOCH 622\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 132.0066 - val_loss: 1095.1102\n",
      "EPOCH 623\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 132.4184 - val_loss: 1107.3462\n",
      "EPOCH 624\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 130.0852 - val_loss: 1112.6750\n",
      "EPOCH 625\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 149.5385 - val_loss: 1101.0461\n",
      "EPOCH 626\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 140.6342 - val_loss: 1094.0197\n",
      "EPOCH 627\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 146.9802 - val_loss: 1101.7671\n",
      "EPOCH 628\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 130.2687 - val_loss: 1106.3442\n",
      "EPOCH 629\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 136.0916 - val_loss: 1102.2640\n",
      "EPOCH 630\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 148.8477 - val_loss: 1101.9174\n",
      "EPOCH 631\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 170.9174 - val_loss: 1092.1743\n",
      "EPOCH 632\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 169.2611 - val_loss: 1085.5953\n",
      "EPOCH 633\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 176.2826 - val_loss: 1100.5142\n",
      "EPOCH 634\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 165.3367 - val_loss: 1095.4055\n",
      "EPOCH 635\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 158.8804 - val_loss: 1091.1273\n",
      "EPOCH 636\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 138.8000 - val_loss: 1092.1957\n",
      "EPOCH 637\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 125.1960 - val_loss: 1092.0149\n",
      "EPOCH 638\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 113.6564 - val_loss: 1092.2115\n",
      "EPOCH 639\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 109.9477 - val_loss: 1093.4753\n",
      "EPOCH 640\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 105.0701 - val_loss: 1092.5293\n",
      "EPOCH 641\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 102.7243 - val_loss: 1093.2367\n",
      "EPOCH 642\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.7672 - val_loss: 1093.6189\n",
      "EPOCH 643\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.7574 - val_loss: 1098.9590\n",
      "EPOCH 644\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 103.1762 - val_loss: 1100.5837\n",
      "EPOCH 645\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 105.1972 - val_loss: 1104.5115\n",
      "EPOCH 646\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.6380 - val_loss: 1101.2220\n",
      "EPOCH 647\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.9564 - val_loss: 1105.4663\n",
      "EPOCH 648\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 103.5046 - val_loss: 1104.8199\n",
      "EPOCH 649\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 107.1756 - val_loss: 1106.1000\n",
      "EPOCH 650\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 107.4566 - val_loss: 1105.7582\n",
      "EPOCH 651\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 102.9032 - val_loss: 1102.6154\n",
      "EPOCH 652\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 111.4318 - val_loss: 1109.0813\n",
      "EPOCH 653\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 117.9757 - val_loss: 1106.5571\n",
      "EPOCH 654\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 122.3407 - val_loss: 1111.3629\n",
      "EPOCH 655\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 124.8874 - val_loss: 1112.5729\n",
      "EPOCH 656\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 119.4495 - val_loss: 1106.5527\n",
      "EPOCH 657\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 124.7579 - val_loss: 1110.7148\n",
      "EPOCH 658\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 119.4457 - val_loss: 1106.6508\n",
      "EPOCH 659\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 115.6671 - val_loss: 1110.7549\n",
      "EPOCH 660\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 113.7937 - val_loss: 1109.7323\n",
      "EPOCH 661\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 108.0203 - val_loss: 1108.1877\n",
      "EPOCH 662\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 108.6954 - val_loss: 1107.0822\n",
      "EPOCH 663\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 102.3772 - val_loss: 1106.0358\n",
      "EPOCH 664\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 98.7706 - val_loss: 1109.6150\n",
      "EPOCH 665\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 96.3108 - val_loss: 1115.2578\n",
      "EPOCH 666\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 95.3680 - val_loss: 1117.6210\n",
      "EPOCH 667\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 92.4677 - val_loss: 1115.3807\n",
      "EPOCH 668\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 90.8394 - val_loss: 1113.0459\n",
      "EPOCH 669\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 90.3521 - val_loss: 1117.2876\n",
      "EPOCH 670\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 91.5120 - val_loss: 1116.7332\n",
      "EPOCH 671\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 90.3404 - val_loss: 1117.6088\n",
      "EPOCH 672\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 89.1717 - val_loss: 1120.3778\n",
      "EPOCH 673\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 88.6970 - val_loss: 1116.7075\n",
      "EPOCH 674\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 87.5625 - val_loss: 1122.7288\n",
      "EPOCH 675\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 87.4546 - val_loss: 1123.1624\n",
      "EPOCH 676\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 87.0674 - val_loss: 1121.8372\n",
      "EPOCH 677\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 87.0826 - val_loss: 1121.6705\n",
      "EPOCH 678\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.7727 - val_loss: 1125.1577\n",
      "EPOCH 679\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.1528 - val_loss: 1124.3584\n",
      "EPOCH 680\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.0500 - val_loss: 1125.6758\n",
      "EPOCH 681\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 85.9572 - val_loss: 1124.5712\n",
      "EPOCH 682\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.1052 - val_loss: 1126.2584\n",
      "EPOCH 683\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.2925 - val_loss: 1128.4822\n",
      "EPOCH 684\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 85.8548 - val_loss: 1126.5714\n",
      "EPOCH 685\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 85.7124 - val_loss: 1130.9324\n",
      "EPOCH 686\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 85.4618 - val_loss: 1128.5424\n",
      "EPOCH 687\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.4986 - val_loss: 1126.6965\n",
      "EPOCH 688\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 87.1142 - val_loss: 1129.7026\n",
      "EPOCH 689\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 88.9565 - val_loss: 1128.2277\n",
      "EPOCH 690\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 88.4113 - val_loss: 1129.7468\n",
      "EPOCH 691\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 87.9402 - val_loss: 1130.8098\n",
      "EPOCH 692\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 87.6296 - val_loss: 1128.6212\n",
      "EPOCH 693\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.5113 - val_loss: 1129.9028\n",
      "EPOCH 694\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 85.1924 - val_loss: 1131.9493\n",
      "EPOCH 695\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 84.8140 - val_loss: 1131.2360\n",
      "EPOCH 696\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 84.5893 - val_loss: 1132.8276\n",
      "EPOCH 697\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 84.0220 - val_loss: 1131.4344\n",
      "EPOCH 698\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 83.5645 - val_loss: 1132.7983\n",
      "EPOCH 699\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 83.3687 - val_loss: 1133.9604\n",
      "EPOCH 700\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 83.1021 - val_loss: 1132.6729\n",
      "EPOCH 701\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 83.0397 - val_loss: 1134.2998\n",
      "EPOCH 702\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 82.8023 - val_loss: 1133.2261\n",
      "EPOCH 703\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 82.6999 - val_loss: 1135.1355\n",
      "EPOCH 704\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 82.9038 - val_loss: 1135.2351\n",
      "EPOCH 705\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 82.8537 - val_loss: 1135.2760\n",
      "EPOCH 706\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 83.3819 - val_loss: 1132.2571\n",
      "EPOCH 707\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 1s 4ms/step - loss: 84.4278 - val_loss: 1137.4268\n",
      "EPOCH 708\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.0965 - val_loss: 1134.0126\n",
      "EPOCH 709\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 88.8011 - val_loss: 1133.5283\n",
      "EPOCH 710\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 93.8661 - val_loss: 1132.7319\n",
      "EPOCH 711\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.1490 - val_loss: 1133.9072\n",
      "EPOCH 712\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 108.8024 - val_loss: 1129.8406\n",
      "EPOCH 713\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 105.4837 - val_loss: 1135.4819\n",
      "EPOCH 714\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 107.2928 - val_loss: 1130.5295\n",
      "EPOCH 715\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 110.8205 - val_loss: 1129.3923\n",
      "EPOCH 716\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 119.9746 - val_loss: 1133.5262\n",
      "EPOCH 717\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 125.4239 - val_loss: 1127.1005\n",
      "EPOCH 718\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 122.8702 - val_loss: 1132.8701\n",
      "EPOCH 719\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 116.4760 - val_loss: 1130.0499\n",
      "EPOCH 720\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 118.5897 - val_loss: 1122.7271\n",
      "EPOCH 721\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 130.1130 - val_loss: 1123.2883\n",
      "EPOCH 722\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 131.7953 - val_loss: 1129.9873\n",
      "EPOCH 723\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 134.5997 - val_loss: 1127.1907\n",
      "EPOCH 724\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 139.1928 - val_loss: 1119.3518\n",
      "EPOCH 725\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 154.2194 - val_loss: 1119.4633\n",
      "EPOCH 726\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 153.0130 - val_loss: 1119.0243\n",
      "EPOCH 727\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 159.0514 - val_loss: 1119.9254\n",
      "EPOCH 728\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 152.3079 - val_loss: 1113.5149\n",
      "EPOCH 729\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 140.8000 - val_loss: 1114.5496\n",
      "EPOCH 730\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 131.3247 - val_loss: 1127.1853\n",
      "EPOCH 731\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 127.8313 - val_loss: 1118.3644\n",
      "EPOCH 732\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 130.8054 - val_loss: 1116.8726\n",
      "EPOCH 733\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 129.2620 - val_loss: 1101.6760\n",
      "EPOCH 734\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 132.5853 - val_loss: 1105.8048\n",
      "EPOCH 735\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 128.5621 - val_loss: 1121.3024\n",
      "EPOCH 736\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 124.1224 - val_loss: 1111.5991\n",
      "EPOCH 737\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 112.9796 - val_loss: 1118.7952\n",
      "EPOCH 738\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 112.3377 - val_loss: 1127.2953\n",
      "EPOCH 739\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 123.9046 - val_loss: 1124.7961\n",
      "EPOCH 740\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 116.1200 - val_loss: 1112.6527\n",
      "EPOCH 741\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 113.8496 - val_loss: 1115.8263\n",
      "EPOCH 742\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 110.2422 - val_loss: 1112.2194\n",
      "EPOCH 743\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 119.8874 - val_loss: 1099.5845\n",
      "EPOCH 744\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 118.6952 - val_loss: 1105.6379\n",
      "EPOCH 745\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 122.4908 - val_loss: 1117.2211\n",
      "EPOCH 746\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 123.3496 - val_loss: 1083.4772\n",
      "EPOCH 747\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 135.1031 - val_loss: 1090.3927\n",
      "EPOCH 748\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 133.9311 - val_loss: 1078.4117\n",
      "EPOCH 749\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 131.6859 - val_loss: 1104.9910\n",
      "EPOCH 750\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 127.5023 - val_loss: 1118.6803\n",
      "EPOCH 751\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 130.3569 - val_loss: 1117.5621\n",
      "EPOCH 752\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 141.2264 - val_loss: 1129.7900\n",
      "EPOCH 753\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 140.1501 - val_loss: 1118.3680\n",
      "EPOCH 754\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 123.6273 - val_loss: 1100.5377\n",
      "EPOCH 755\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 113.1488 - val_loss: 1108.9259\n",
      "EPOCH 756\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 108.1404 - val_loss: 1105.0376\n",
      "EPOCH 757\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.2103 - val_loss: 1105.4526\n",
      "EPOCH 758\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 96.0612 - val_loss: 1114.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 759\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 93.1358 - val_loss: 1110.7697\n",
      "EPOCH 760\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 91.8809 - val_loss: 1113.8319\n",
      "EPOCH 761\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 89.3185 - val_loss: 1114.1074\n",
      "EPOCH 762\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 89.7095 - val_loss: 1111.0135\n",
      "EPOCH 763\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 88.5818 - val_loss: 1114.0503\n",
      "EPOCH 764\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.7841 - val_loss: 1112.6067\n",
      "EPOCH 765\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 85.6910 - val_loss: 1111.1841\n",
      "EPOCH 766\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 85.0132 - val_loss: 1111.1658\n",
      "EPOCH 767\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 85.1520 - val_loss: 1110.9528\n",
      "EPOCH 768\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.0237 - val_loss: 1112.7219\n",
      "EPOCH 769\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 88.7513 - val_loss: 1114.9955\n",
      "EPOCH 770\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 90.9240 - val_loss: 1114.7136\n",
      "EPOCH 771\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 89.1736 - val_loss: 1112.8544\n",
      "EPOCH 772\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 88.6153 - val_loss: 1113.9923\n",
      "EPOCH 773\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 89.2563 - val_loss: 1117.6965\n",
      "EPOCH 774\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 89.8791 - val_loss: 1117.2672\n",
      "EPOCH 775\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 90.1077 - val_loss: 1115.7529\n",
      "EPOCH 776\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 90.4764 - val_loss: 1124.5780\n",
      "EPOCH 777\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 89.3823 - val_loss: 1118.7793\n",
      "EPOCH 778\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 87.3738 - val_loss: 1115.8643\n",
      "EPOCH 779\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.9205 - val_loss: 1116.4064\n",
      "EPOCH 780\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 87.0903 - val_loss: 1117.1829\n",
      "EPOCH 781\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 84.7108 - val_loss: 1123.8671\n",
      "EPOCH 782\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.5077 - val_loss: 1117.9492\n",
      "EPOCH 783\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.5191 - val_loss: 1116.5208\n",
      "EPOCH 784\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.4497 - val_loss: 1119.3813\n",
      "EPOCH 785\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 87.7678 - val_loss: 1123.2723\n",
      "EPOCH 786\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 91.9309 - val_loss: 1120.3429\n",
      "EPOCH 787\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 92.1398 - val_loss: 1121.1541\n",
      "EPOCH 788\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 95.3988 - val_loss: 1121.5247\n",
      "EPOCH 789\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 103.9998 - val_loss: 1124.4314\n",
      "EPOCH 790\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 97.8831 - val_loss: 1125.7358\n",
      "EPOCH 791\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 99.1121 - val_loss: 1116.6724\n",
      "EPOCH 792\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 111.3932 - val_loss: 1124.5997\n",
      "EPOCH 793\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 113.5216 - val_loss: 1135.8033\n",
      "EPOCH 794\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 107.6881 - val_loss: 1122.0520\n",
      "EPOCH 795\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 105.3540 - val_loss: 1125.5581\n",
      "EPOCH 796\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 109.7443 - val_loss: 1125.7166\n",
      "EPOCH 797\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 112.9016 - val_loss: 1119.8629\n",
      "EPOCH 798\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 108.9583 - val_loss: 1120.2998\n",
      "EPOCH 799\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 104.7850 - val_loss: 1121.8302\n",
      "EPOCH 800\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.9974 - val_loss: 1127.2312\n",
      "EPOCH 801\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 95.9165 - val_loss: 1125.0386\n",
      "EPOCH 802\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 92.6897 - val_loss: 1120.2332\n",
      "EPOCH 803\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 94.2790 - val_loss: 1120.5670\n",
      "EPOCH 804\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 89.0186 - val_loss: 1120.1282\n",
      "EPOCH 805\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.8185 - val_loss: 1120.6559\n",
      "EPOCH 806\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 90.3235 - val_loss: 1124.2135\n",
      "EPOCH 807\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 88.6696 - val_loss: 1128.5298\n",
      "EPOCH 808\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 91.0026 - val_loss: 1119.7382\n",
      "EPOCH 809\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 99.3230 - val_loss: 1126.9584\n",
      "EPOCH 810\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 93.6673 - val_loss: 1126.3070\n",
      "EPOCH 811\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 91.8304 - val_loss: 1119.0916\n",
      "EPOCH 812\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 88.1688 - val_loss: 1128.3003\n",
      "EPOCH 813\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 89.7642 - val_loss: 1126.2025\n",
      "EPOCH 814\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 90.1931 - val_loss: 1125.4530\n",
      "EPOCH 815\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 88.1248 - val_loss: 1127.1625\n",
      "EPOCH 816\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 91.0227 - val_loss: 1122.8481\n",
      "EPOCH 817\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 92.5778 - val_loss: 1127.6913\n",
      "EPOCH 818\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 94.3374 - val_loss: 1135.2739\n",
      "EPOCH 819\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.8720 - val_loss: 1124.4152\n",
      "EPOCH 820\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 99.5339 - val_loss: 1124.0287\n",
      "EPOCH 821\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 105.8387 - val_loss: 1130.8752\n",
      "EPOCH 822\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 123.7220 - val_loss: 1133.2180\n",
      "EPOCH 823\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 136.1501 - val_loss: 1131.2889\n",
      "EPOCH 824\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 123.2810 - val_loss: 1130.4120\n",
      "EPOCH 825\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 123.2875 - val_loss: 1114.2645\n",
      "EPOCH 826\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 138.7941 - val_loss: 1127.8473\n",
      "EPOCH 827\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 138.2905 - val_loss: 1126.9321\n",
      "EPOCH 828\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 129.4930 - val_loss: 1117.3152\n",
      "EPOCH 829\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 124.6552 - val_loss: 1116.9387\n",
      "EPOCH 830\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 134.4181 - val_loss: 1110.3414\n",
      "EPOCH 831\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 150.7556 - val_loss: 1127.5483\n",
      "EPOCH 832\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 158.6120 - val_loss: 1108.9603\n",
      "EPOCH 833\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 165.5763 - val_loss: 1118.3051\n",
      "EPOCH 834\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 175.3153 - val_loss: 1113.1188\n",
      "EPOCH 835\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 153.6641 - val_loss: 1112.3962\n",
      "EPOCH 836\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 127.7599 - val_loss: 1113.1588\n",
      "EPOCH 837\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 115.7163 - val_loss: 1109.0884\n",
      "EPOCH 838\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 110.4074 - val_loss: 1114.5231\n",
      "EPOCH 839\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 109.0346 - val_loss: 1112.2993\n",
      "EPOCH 840\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 108.5104 - val_loss: 1114.4323\n",
      "EPOCH 841\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 105.9749 - val_loss: 1121.6647\n",
      "EPOCH 842\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 99.5562 - val_loss: 1111.1390\n",
      "EPOCH 843\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.4874 - val_loss: 1118.8333\n",
      "EPOCH 844\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 102.0610 - val_loss: 1108.8148\n",
      "EPOCH 845\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 116.1231 - val_loss: 1126.0565\n",
      "EPOCH 846\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 122.4731 - val_loss: 1114.3872\n",
      "EPOCH 847\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 121.8827 - val_loss: 1111.7015\n",
      "EPOCH 848\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 115.3331 - val_loss: 1117.2396\n",
      "EPOCH 849\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 112.1394 - val_loss: 1120.4236\n",
      "EPOCH 850\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 102.7220 - val_loss: 1113.7834\n",
      "EPOCH 851\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 110.7045 - val_loss: 1120.0927\n",
      "EPOCH 852\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 108.1169 - val_loss: 1117.0760\n",
      "EPOCH 853\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.0922 - val_loss: 1118.7546\n",
      "EPOCH 854\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 93.6523 - val_loss: 1118.0701\n",
      "EPOCH 855\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 89.0560 - val_loss: 1122.5695\n",
      "EPOCH 856\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 85.4981 - val_loss: 1125.4666\n",
      "EPOCH 857\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 82.5614 - val_loss: 1122.1539\n",
      "EPOCH 858\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 80.9041 - val_loss: 1117.4982\n",
      "EPOCH 859\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 79.4341 - val_loss: 1121.8007\n",
      "EPOCH 860\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 78.1774 - val_loss: 1123.1392\n",
      "EPOCH 861\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 78.1905 - val_loss: 1125.9224\n",
      "EPOCH 862\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 1s 4ms/step - loss: 76.7545 - val_loss: 1126.0107\n",
      "EPOCH 863\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 76.3048 - val_loss: 1127.7208\n",
      "EPOCH 864\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 76.2118 - val_loss: 1126.3510\n",
      "EPOCH 865\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 76.0100 - val_loss: 1126.0067\n",
      "EPOCH 866\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 75.5922 - val_loss: 1129.4541\n",
      "EPOCH 867\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 75.2534 - val_loss: 1127.5277\n",
      "EPOCH 868\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 76.4827 - val_loss: 1130.1617\n",
      "EPOCH 869\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 76.4088 - val_loss: 1129.1318\n",
      "EPOCH 870\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 76.6072 - val_loss: 1129.1559\n",
      "EPOCH 871\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 76.2651 - val_loss: 1133.0347\n",
      "EPOCH 872\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 76.6386 - val_loss: 1130.6328\n",
      "EPOCH 873\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 77.2906 - val_loss: 1129.6948\n",
      "EPOCH 874\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 77.8951 - val_loss: 1133.9661\n",
      "EPOCH 875\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 81.0653 - val_loss: 1127.6176\n",
      "EPOCH 876\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 88.6179 - val_loss: 1131.0452\n",
      "EPOCH 877\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 89.8530 - val_loss: 1138.0828\n",
      "EPOCH 878\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 94.3685 - val_loss: 1128.9272\n",
      "EPOCH 879\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 103.4838 - val_loss: 1130.2700\n",
      "EPOCH 880\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 104.1084 - val_loss: 1126.9211\n",
      "EPOCH 881\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.0828 - val_loss: 1127.1637\n",
      "EPOCH 882\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 105.8228 - val_loss: 1136.4882\n",
      "EPOCH 883\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 108.9090 - val_loss: 1132.5680\n",
      "EPOCH 884\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 112.0030 - val_loss: 1124.6509\n",
      "EPOCH 885\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 108.0705 - val_loss: 1127.0691\n",
      "EPOCH 886\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 98.2377 - val_loss: 1136.0642\n",
      "EPOCH 887\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 96.8281 - val_loss: 1139.6555\n",
      "EPOCH 888\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 108.7595 - val_loss: 1129.8975\n",
      "EPOCH 889\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 118.9746 - val_loss: 1128.6272\n",
      "EPOCH 890\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 114.5939 - val_loss: 1129.9137\n",
      "EPOCH 891\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 106.2557 - val_loss: 1126.6406\n",
      "EPOCH 892\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 108.4000 - val_loss: 1120.4814\n",
      "EPOCH 893\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 97.2751 - val_loss: 1129.4199\n",
      "EPOCH 894\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 91.1311 - val_loss: 1130.3251\n",
      "EPOCH 895\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 89.5360 - val_loss: 1131.7261\n",
      "EPOCH 896\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 89.2992 - val_loss: 1128.4259\n",
      "EPOCH 897\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.3156 - val_loss: 1132.0243\n",
      "EPOCH 898\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 81.9593 - val_loss: 1134.7188\n",
      "EPOCH 899\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 82.1848 - val_loss: 1133.7747\n",
      "EPOCH 900\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 79.2086 - val_loss: 1133.7832\n",
      "EPOCH 901\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 78.9322 - val_loss: 1140.0359\n",
      "EPOCH 902\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 77.1427 - val_loss: 1137.8335\n",
      "EPOCH 903\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 77.4515 - val_loss: 1138.8044\n",
      "EPOCH 904\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 77.4743 - val_loss: 1140.2866\n",
      "EPOCH 905\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 79.3643 - val_loss: 1139.5155\n",
      "EPOCH 906\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 83.9795 - val_loss: 1137.4973\n",
      "EPOCH 907\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 84.7812 - val_loss: 1137.4006\n",
      "EPOCH 908\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 84.9066 - val_loss: 1138.5422\n",
      "EPOCH 909\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 82.7145 - val_loss: 1141.9471\n",
      "EPOCH 910\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.7157 - val_loss: 1139.6346\n",
      "EPOCH 911\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.9810 - val_loss: 1134.2008\n",
      "EPOCH 912\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.8649 - val_loss: 1137.9489\n",
      "EPOCH 913\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 98.6326 - val_loss: 1136.8977\n",
      "EPOCH 914\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 1s 4ms/step - loss: 98.7499 - val_loss: 1140.9253\n",
      "EPOCH 915\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 98.7061 - val_loss: 1148.8734\n",
      "EPOCH 916\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 94.0360 - val_loss: 1129.8988\n",
      "EPOCH 917\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 93.3980 - val_loss: 1136.3022\n",
      "EPOCH 918\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 90.2457 - val_loss: 1140.7147\n",
      "EPOCH 919\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 88.2530 - val_loss: 1140.4310\n",
      "EPOCH 920\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 96.9253 - val_loss: 1141.5991\n",
      "EPOCH 921\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 93.6478 - val_loss: 1138.3864\n",
      "EPOCH 922\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 89.6396 - val_loss: 1140.8833\n",
      "EPOCH 923\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 91.5727 - val_loss: 1147.0977\n",
      "EPOCH 924\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 85.9828 - val_loss: 1139.9137\n",
      "EPOCH 925\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 87.1014 - val_loss: 1136.9099\n",
      "EPOCH 926\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 82.8136 - val_loss: 1146.5453\n",
      "EPOCH 927\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 79.3887 - val_loss: 1139.1483\n",
      "EPOCH 928\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 78.6341 - val_loss: 1134.0060\n",
      "EPOCH 929\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 77.5202 - val_loss: 1143.0250\n",
      "EPOCH 930\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 74.9944 - val_loss: 1142.3002\n",
      "EPOCH 931\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 77.7374 - val_loss: 1139.6677\n",
      "EPOCH 932\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 76.6493 - val_loss: 1136.0420\n",
      "EPOCH 933\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 79.8723 - val_loss: 1136.8464\n",
      "EPOCH 934\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 76.8937 - val_loss: 1138.0981\n",
      "EPOCH 935\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 78.6889 - val_loss: 1143.2694\n",
      "EPOCH 936\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 79.4296 - val_loss: 1139.6930\n",
      "EPOCH 937\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 84.0055 - val_loss: 1136.7373\n",
      "EPOCH 938\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 82.9511 - val_loss: 1139.8942\n",
      "EPOCH 939\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 88.9315 - val_loss: 1147.6843\n",
      "EPOCH 940\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 88.3808 - val_loss: 1143.0182\n",
      "EPOCH 941\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 84.7067 - val_loss: 1142.6935\n",
      "EPOCH 942\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 94.1687 - val_loss: 1146.9404\n",
      "EPOCH 943\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 110.5713 - val_loss: 1136.1796\n",
      "EPOCH 944\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 110.7946 - val_loss: 1140.5028\n",
      "EPOCH 945\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 103.9692 - val_loss: 1141.9607\n",
      "EPOCH 946\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 110.6396 - val_loss: 1140.8647\n",
      "EPOCH 947\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 104.6930 - val_loss: 1139.9806\n",
      "EPOCH 948\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 104.7421 - val_loss: 1143.6520\n",
      "EPOCH 949\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 89.7491 - val_loss: 1133.7808\n",
      "EPOCH 950\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 90.9688 - val_loss: 1134.4684\n",
      "EPOCH 951\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 90.7478 - val_loss: 1138.9043\n",
      "EPOCH 952\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 87.2446 - val_loss: 1139.2850\n",
      "EPOCH 953\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 87.9009 - val_loss: 1143.9449\n",
      "EPOCH 954\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 87.1589 - val_loss: 1139.5719\n",
      "EPOCH 955\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 83.9393 - val_loss: 1144.0664\n",
      "EPOCH 956\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 77.8956 - val_loss: 1142.3610\n",
      "EPOCH 957\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 78.0205 - val_loss: 1139.2339\n",
      "EPOCH 958\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 76.2260 - val_loss: 1144.2906\n",
      "EPOCH 959\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 75.4652 - val_loss: 1144.9053\n",
      "EPOCH 960\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 73.4495 - val_loss: 1139.8728\n",
      "EPOCH 961\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 72.5838 - val_loss: 1138.7928\n",
      "EPOCH 962\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 71.5320 - val_loss: 1145.1500\n",
      "EPOCH 963\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 71.8955 - val_loss: 1143.2305\n",
      "EPOCH 964\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 72.6787 - val_loss: 1143.4695\n",
      "EPOCH 965\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 72.6356 - val_loss: 1147.7418\n",
      "EPOCH 966\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 1s 4ms/step - loss: 72.5936 - val_loss: 1143.1257\n",
      "EPOCH 967\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 73.6600 - val_loss: 1147.9083\n",
      "EPOCH 968\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 73.7899 - val_loss: 1148.4432\n",
      "EPOCH 969\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 76.0665 - val_loss: 1142.4563\n",
      "EPOCH 970\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 75.4158 - val_loss: 1144.9886\n",
      "EPOCH 971\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 73.6552 - val_loss: 1150.9172\n",
      "EPOCH 972\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 82.3664 - val_loss: 1144.0422\n",
      "EPOCH 973\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 85.9862 - val_loss: 1140.4133\n",
      "EPOCH 974\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 87.3766 - val_loss: 1146.9114\n",
      "EPOCH 975\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 94.7568 - val_loss: 1148.4253\n",
      "EPOCH 976\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 99.5022 - val_loss: 1137.6718\n",
      "EPOCH 977\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 113.5248 - val_loss: 1151.0344\n",
      "EPOCH 978\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 107.7193 - val_loss: 1148.8103\n",
      "EPOCH 979\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 102.6305 - val_loss: 1144.8367\n",
      "EPOCH 980\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 98.8596 - val_loss: 1145.0747\n",
      "EPOCH 981\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 95.0187 - val_loss: 1137.2056\n",
      "EPOCH 982\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.8202 - val_loss: 1153.7432\n",
      "EPOCH 983\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 96.0072 - val_loss: 1143.5073\n",
      "EPOCH 984\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 98.7431 - val_loss: 1138.2096\n",
      "EPOCH 985\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 97.6887 - val_loss: 1147.1503\n",
      "EPOCH 986\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 103.1730 - val_loss: 1138.9893\n",
      "EPOCH 987\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 109.5258 - val_loss: 1148.8953\n",
      "EPOCH 988\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 107.6199 - val_loss: 1148.5194\n",
      "EPOCH 989\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 102.2347 - val_loss: 1150.0575\n",
      "EPOCH 990\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.0792 - val_loss: 1147.7301\n",
      "EPOCH 991\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 117.2509 - val_loss: 1138.7311\n",
      "EPOCH 992\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 136.7331 - val_loss: 1139.7649\n",
      "EPOCH 993\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 130.8352 - val_loss: 1144.9574\n",
      "EPOCH 994\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 121.3456 - val_loss: 1148.3070\n",
      "EPOCH 995\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 133.5853 - val_loss: 1137.4219\n",
      "EPOCH 996\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 141.6554 - val_loss: 1128.5532\n",
      "EPOCH 997\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 172.9597 - val_loss: 1135.6293\n",
      "EPOCH 998\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 181.4436 - val_loss: 1131.1194\n",
      "EPOCH 999\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 169.9461 - val_loss: 1143.1078\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TRAIN LOOP\n",
    "for epoch in range(1000):\n",
    "    print('EPOCH %d' % (epoch))\n",
    "    hist = seq.train(X_train=X_train[:, 0:20, :], \n",
    "                     Y_train=X_train[:,20:, :], \n",
    "                     X_val=X_val[:, 0:20, :], \n",
    "                     Y_val=X_val[:, 20:, :], \n",
    "                     epochs=1, \n",
    "                     batch_size=32\n",
    "                     )\n",
    "    history[\"loss\"].append(hist.history[\"loss\"][0])\n",
    "    history[\"val_loss\"].append(hist.history[\"val_loss\"][0])\n",
    "    if epoch % 500 == 0:\n",
    "        i = random.randint(0, X_train.shape[0]-1)\n",
    "        X, Y = [], []\n",
    "        x = X_train[i, 0:20, :]\n",
    "        X.append(x)\n",
    "        X = np.array(X)\n",
    "        y = X_train[i, 20:, :]\n",
    "        Y.append(y)\n",
    "        Y = np.array(Y)\n",
    "        Y_hat = seq.model.predict(X)\n",
    "        Y_decoded = ae.decode_series(Y)\n",
    "        Y_hat_decoded = ae.decode_series(Y_hat)\n",
    "        compare_images_as_video(Y_decoded[0], Y_hat_decoded[0])\n",
    "    seq.save_weights(root+\"/../models/seq2seq_many_to_many_recent_past_future_32.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y, Y_hat, embedding, i = build_future_from_past(seq_model=seq, ae_model=ae, X=X_train, past_horizon=20, future_horizon=80)\n",
    "compare_images_as_video(Y, Y_hat)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

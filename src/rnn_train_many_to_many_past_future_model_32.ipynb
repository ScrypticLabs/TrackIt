{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS NOTEBOOK TRAINS THE RNN LSTM MANY-TO-MANY MODEL WHERE PAST AND FUTURE ARE EQUAL LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/abhi/anaconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/abhi/anaconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/abhi/anaconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/abhi/anaconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/abhi/anaconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/abhi/anaconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from data_loader import DataLoader\n",
    "from utils.visualize import show_images_in_grid, show_images_as_video, show_reconstructions, compare_images_as_video\n",
    "from cnn import Autoencoder\n",
    "from rnn_many_to_many import Seq2Seq\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_data_loader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_data_loader.X_train = np.load(root+\"/../datasets/train/32/X_train_normalized.npy\")\n",
    "rnn_data_loader.X_val = np.load(root+\"/../datasets/val/32/X_val_normalized.npy\")\n",
    "rnn_data_loader.X_test = np.load(root+\"/../datasets/test/32/X_test_normalized.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LET'S COMPUTE THE EMBEDDINGS FROM THE DATA AND TRAINED AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abhi/anaconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "ae = Autoencoder()\n",
    "ae.build_model(input_dim=(32, 32, 3), latent_dim=(64,))\n",
    "ae.set_weights(root+\"/../models/autoencoder_32.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ae.encode_series(rnn_data_loader.X_train)\n",
    "X_val = ae.encode_series(rnn_data_loader.X_val)\n",
    "X_test = ae.encode_series(rnn_data_loader.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 100, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = Seq2Seq()\n",
    "seq.build_model(input_length=50, input_dim=64, latent_dim=(256,), output_length=50, output_dim=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq.set_weights(root+\"/../models/seq2seq_many_to_many_past_future_32.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 50, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50, 1024)          4460544   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50, 512)           3147776   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 256)               787456    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50, 512)           1574912   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 50, 1024)          6295552   \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 50, 64)            65600     \n",
      "=================================================================\n",
      "Total params: 16,331,840\n",
      "Trainable params: 16,331,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    \"loss\" : [],\n",
    "    \"val_loss\" : []\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 501\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 231.3343 - val_loss: 1009.1931\n",
      "EPOCH 502\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 251.4326 - val_loss: 1020.1851\n",
      "EPOCH 503\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 252.9366 - val_loss: 1017.0817\n",
      "EPOCH 504\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 250.2757 - val_loss: 1014.5906\n",
      "EPOCH 505\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 238.6925 - val_loss: 1017.3729\n",
      "EPOCH 506\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 232.4664 - val_loss: 1011.9272\n",
      "EPOCH 507\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 229.2324 - val_loss: 1012.7549\n",
      "EPOCH 508\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 224.0973 - val_loss: 1008.4601\n",
      "EPOCH 509\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 221.7895 - val_loss: 1019.7654\n",
      "EPOCH 510\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 218.7151 - val_loss: 1010.5482\n",
      "EPOCH 511\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 212.7610 - val_loss: 1017.6512\n",
      "EPOCH 512\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 210.0564 - val_loss: 1008.6564\n",
      "EPOCH 513\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 207.8290 - val_loss: 1007.8820\n",
      "EPOCH 514\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 208.7190 - val_loss: 1012.4421\n",
      "EPOCH 515\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 212.9656 - val_loss: 1016.2713\n",
      "EPOCH 516\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 211.7897 - val_loss: 1019.9680\n",
      "EPOCH 517\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 222.1602 - val_loss: 1015.6481\n",
      "EPOCH 518\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 220.2407 - val_loss: 1012.8410\n",
      "EPOCH 519\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 215.6312 - val_loss: 1012.0109\n",
      "EPOCH 520\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 213.7201 - val_loss: 1010.2700\n",
      "EPOCH 521\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 215.7845 - val_loss: 1014.2528\n",
      "EPOCH 522\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 215.7037 - val_loss: 1005.1600\n",
      "EPOCH 523\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 211.7908 - val_loss: 1018.8805\n",
      "EPOCH 524\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 210.4851 - val_loss: 1017.3561\n",
      "EPOCH 525\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 208.8197 - val_loss: 1016.7954\n",
      "EPOCH 526\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 215.9832 - val_loss: 1014.0757\n",
      "EPOCH 527\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 214.1429 - val_loss: 1018.8729\n",
      "EPOCH 528\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 208.9276 - val_loss: 1020.4276\n",
      "EPOCH 529\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 207.0187 - val_loss: 1020.1631\n",
      "EPOCH 530\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 204.5786 - val_loss: 1017.2101\n",
      "EPOCH 531\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 200.2996 - val_loss: 1017.8003\n",
      "EPOCH 532\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 198.6336 - val_loss: 1014.9126\n",
      "EPOCH 533\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 196.5226 - val_loss: 1019.6393\n",
      "EPOCH 534\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 196.6553 - val_loss: 1021.1771\n",
      "EPOCH 535\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 195.2309 - val_loss: 1019.5851\n",
      "EPOCH 536\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 196.7206 - val_loss: 1021.1104\n",
      "EPOCH 537\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 194.9520 - val_loss: 1015.2716\n",
      "EPOCH 538\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 195.6302 - val_loss: 1017.9564\n",
      "EPOCH 539\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 195.2262 - val_loss: 1019.1412\n",
      "EPOCH 540\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 193.7448 - val_loss: 1023.9706\n",
      "EPOCH 541\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 191.7200 - val_loss: 1021.4949\n",
      "EPOCH 542\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 191.2738 - val_loss: 1021.1408\n",
      "EPOCH 543\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 189.8502 - val_loss: 1021.0708\n",
      "EPOCH 544\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 188.3122 - val_loss: 1022.6700\n",
      "EPOCH 545\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 186.4040 - val_loss: 1023.8063\n",
      "EPOCH 546\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 185.8193 - val_loss: 1023.6091\n",
      "EPOCH 547\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 184.1052 - val_loss: 1026.4449\n",
      "EPOCH 548\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 183.4543 - val_loss: 1023.1598\n",
      "EPOCH 549\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 182.0320 - val_loss: 1023.4716\n",
      "EPOCH 550\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 181.3984 - val_loss: 1026.4642\n",
      "EPOCH 551\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 181.1055 - val_loss: 1024.4410\n",
      "EPOCH 552\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 180.0933 - val_loss: 1026.7913\n",
      "EPOCH 553\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 179.6941 - val_loss: 1026.0970\n",
      "EPOCH 554\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 179.3264 - val_loss: 1026.2200\n",
      "EPOCH 555\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 179.0481 - val_loss: 1026.1498\n",
      "EPOCH 556\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 178.7478 - val_loss: 1030.5602\n",
      "EPOCH 557\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 178.9390 - val_loss: 1027.3604\n",
      "EPOCH 558\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 179.0776 - val_loss: 1032.2137\n",
      "EPOCH 559\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 177.4816 - val_loss: 1030.5767\n",
      "EPOCH 560\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 177.5968 - val_loss: 1030.2539\n",
      "EPOCH 561\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 179.2464 - val_loss: 1029.5121\n",
      "EPOCH 562\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 179.5552 - val_loss: 1035.7401\n",
      "EPOCH 563\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 179.7283 - val_loss: 1028.7134\n",
      "EPOCH 564\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 180.7972 - val_loss: 1034.9027\n",
      "EPOCH 565\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 179.9365 - val_loss: 1037.3221\n",
      "EPOCH 566\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 180.8401 - val_loss: 1033.3011\n",
      "EPOCH 567\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 179.1625 - val_loss: 1032.4036\n",
      "EPOCH 568\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 180.2809 - val_loss: 1035.8987\n",
      "EPOCH 569\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 177.8391 - val_loss: 1034.3207\n",
      "EPOCH 570\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 178.3848 - val_loss: 1031.1429\n",
      "EPOCH 571\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 183.1848 - val_loss: 1031.3900\n",
      "EPOCH 572\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 187.8176 - val_loss: 1033.2062\n",
      "EPOCH 573\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 202.7894 - val_loss: 1039.8541\n",
      "EPOCH 574\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 206.9562 - val_loss: 1046.9608\n",
      "EPOCH 575\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 205.4295 - val_loss: 1019.8534\n",
      "EPOCH 576\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 200.5652 - val_loss: 1038.0248\n",
      "EPOCH 577\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 204.4485 - val_loss: 1035.2852\n",
      "EPOCH 578\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 200.4098 - val_loss: 1045.7721\n",
      "EPOCH 579\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 202.8742 - val_loss: 1038.2306\n",
      "EPOCH 580\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 200.7320 - val_loss: 1032.0123\n",
      "EPOCH 581\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 206.9998 - val_loss: 1029.7704\n",
      "EPOCH 582\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 201.9370 - val_loss: 1034.6541\n",
      "EPOCH 583\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 205.6491 - val_loss: 1040.4319\n",
      "EPOCH 584\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 209.6346 - val_loss: 1037.5851\n",
      "EPOCH 585\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 203.5840 - val_loss: 1027.6652\n",
      "EPOCH 586\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 203.0800 - val_loss: 1037.8660\n",
      "EPOCH 587\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 202.5891 - val_loss: 1037.9905\n",
      "EPOCH 588\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 200.9005 - val_loss: 1029.3779\n",
      "EPOCH 589\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 215.1376 - val_loss: 1028.7671\n",
      "EPOCH 590\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 219.1343 - val_loss: 1037.9681\n",
      "EPOCH 591\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 223.3896 - val_loss: 1030.1234\n",
      "EPOCH 592\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 227.3080 - val_loss: 1026.4661\n",
      "EPOCH 593\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 226.7709 - val_loss: 1051.3956\n",
      "EPOCH 594\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 224.0024 - val_loss: 1028.7649\n",
      "EPOCH 595\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 233.7020 - val_loss: 1040.1301\n",
      "EPOCH 596\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 222.0502 - val_loss: 1025.8171\n",
      "EPOCH 597\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 203.7812 - val_loss: 1028.5920\n",
      "EPOCH 598\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 204.4589 - val_loss: 1044.8822\n",
      "EPOCH 599\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 203.9535 - val_loss: 1035.1775\n",
      "EPOCH 600\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 190.3700 - val_loss: 1023.0946\n",
      "EPOCH 601\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 184.8001 - val_loss: 1027.3445\n",
      "EPOCH 602\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 180.4270 - val_loss: 1028.7941\n",
      "EPOCH 603\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 179.2995 - val_loss: 1025.5520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 604\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 176.7680 - val_loss: 1031.2983\n",
      "EPOCH 605\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 173.4313 - val_loss: 1032.9463\n",
      "EPOCH 606\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 170.8591 - val_loss: 1029.5289\n",
      "EPOCH 607\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 171.9943 - val_loss: 1030.4054\n",
      "EPOCH 608\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 175.4266 - val_loss: 1032.7545\n",
      "EPOCH 609\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 175.8975 - val_loss: 1034.6924\n",
      "EPOCH 610\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 176.3962 - val_loss: 1039.6521\n",
      "EPOCH 611\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 176.6877 - val_loss: 1033.1266\n",
      "EPOCH 612\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 178.7473 - val_loss: 1035.0198\n",
      "EPOCH 613\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 178.3301 - val_loss: 1039.8900\n",
      "EPOCH 614\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 178.2748 - val_loss: 1032.5442\n",
      "EPOCH 615\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 186.0192 - val_loss: 1035.5626\n",
      "EPOCH 616\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 189.2773 - val_loss: 1037.3013\n",
      "EPOCH 617\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 193.6493 - val_loss: 1037.7699\n",
      "EPOCH 618\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 188.9216 - val_loss: 1043.1112\n",
      "EPOCH 619\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 187.3188 - val_loss: 1029.4287\n",
      "EPOCH 620\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 177.1676 - val_loss: 1035.4193\n",
      "EPOCH 621\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 175.1006 - val_loss: 1034.8781\n",
      "EPOCH 622\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 170.0568 - val_loss: 1039.6500\n",
      "EPOCH 623\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 167.1624 - val_loss: 1034.0980\n",
      "EPOCH 624\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 165.3994 - val_loss: 1036.0399\n",
      "EPOCH 625\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 163.4585 - val_loss: 1034.0410\n",
      "EPOCH 626\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 161.0445 - val_loss: 1037.8834\n",
      "EPOCH 627\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 160.0773 - val_loss: 1041.2159\n",
      "EPOCH 628\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 158.7540 - val_loss: 1040.9403\n",
      "EPOCH 629\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 158.1334 - val_loss: 1037.8126\n",
      "EPOCH 630\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 157.6683 - val_loss: 1037.0538\n",
      "EPOCH 631\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 157.4392 - val_loss: 1041.2936\n",
      "EPOCH 632\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 157.8566 - val_loss: 1040.5692\n",
      "EPOCH 633\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 156.3986 - val_loss: 1040.2604\n",
      "EPOCH 634\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 155.7001 - val_loss: 1040.8801\n",
      "EPOCH 635\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 155.2894 - val_loss: 1041.8752\n",
      "EPOCH 636\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 155.2514 - val_loss: 1044.5172\n",
      "EPOCH 637\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 155.6452 - val_loss: 1041.4590\n",
      "EPOCH 638\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 155.0783 - val_loss: 1043.4556\n",
      "EPOCH 639\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 155.3121 - val_loss: 1041.9360\n",
      "EPOCH 640\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 155.6568 - val_loss: 1044.0942\n",
      "EPOCH 641\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 155.9709 - val_loss: 1042.5731\n",
      "EPOCH 642\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 156.4260 - val_loss: 1041.9126\n",
      "EPOCH 643\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 158.3382 - val_loss: 1041.5798\n",
      "EPOCH 644\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 158.4374 - val_loss: 1048.8020\n",
      "EPOCH 645\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 157.2204 - val_loss: 1040.5367\n",
      "EPOCH 646\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 155.9996 - val_loss: 1049.4346\n",
      "EPOCH 647\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 156.0127 - val_loss: 1047.6917\n",
      "EPOCH 648\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 156.4403 - val_loss: 1049.8590\n",
      "EPOCH 649\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 156.5495 - val_loss: 1043.3180\n",
      "EPOCH 650\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 154.7985 - val_loss: 1052.0985\n",
      "EPOCH 651\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 154.1326 - val_loss: 1043.8774\n",
      "EPOCH 652\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 153.9269 - val_loss: 1046.5057\n",
      "EPOCH 653\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 153.3359 - val_loss: 1049.3751\n",
      "EPOCH 654\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 153.3551 - val_loss: 1049.7181\n",
      "EPOCH 655\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 152.9707 - val_loss: 1047.6112\n",
      "EPOCH 656\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 153.0090 - val_loss: 1056.8571\n",
      "EPOCH 657\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 152.1189 - val_loss: 1045.8563\n",
      "EPOCH 658\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 151.9143 - val_loss: 1054.4901\n",
      "EPOCH 659\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 151.4126 - val_loss: 1048.0170\n",
      "EPOCH 660\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 151.7436 - val_loss: 1050.6775\n",
      "EPOCH 661\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 151.8394 - val_loss: 1045.1254\n",
      "EPOCH 662\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 150.3037 - val_loss: 1055.3743\n",
      "EPOCH 663\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 150.4540 - val_loss: 1051.8386\n",
      "EPOCH 664\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 151.0960 - val_loss: 1054.1708\n",
      "EPOCH 665\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 152.3864 - val_loss: 1045.7444\n",
      "EPOCH 666\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 155.3319 - val_loss: 1050.7052\n",
      "EPOCH 667\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 157.3611 - val_loss: 1055.4128\n",
      "EPOCH 668\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 155.9778 - val_loss: 1057.4980\n",
      "EPOCH 669\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 156.5423 - val_loss: 1048.2021\n",
      "EPOCH 670\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 164.6330 - val_loss: 1057.0071\n",
      "EPOCH 671\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 171.6557 - val_loss: 1055.1683\n",
      "EPOCH 672\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 176.8015 - val_loss: 1060.2069\n",
      "EPOCH 673\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 178.3396 - val_loss: 1045.5751\n",
      "EPOCH 674\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 188.5412 - val_loss: 1058.8253\n",
      "EPOCH 675\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 192.0551 - val_loss: 1056.2360\n",
      "EPOCH 676\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 188.9888 - val_loss: 1044.3174\n",
      "EPOCH 677\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 189.5961 - val_loss: 1053.2961\n",
      "EPOCH 678\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 186.5245 - val_loss: 1059.1826\n",
      "EPOCH 679\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 176.6933 - val_loss: 1063.7064\n",
      "EPOCH 680\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 172.2245 - val_loss: 1052.6349\n",
      "EPOCH 681\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 164.9062 - val_loss: 1060.7744\n",
      "EPOCH 682\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 163.7958 - val_loss: 1057.1481\n",
      "EPOCH 683\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 158.5456 - val_loss: 1048.7878\n",
      "EPOCH 684\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 159.3908 - val_loss: 1054.8948\n",
      "EPOCH 685\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 156.2279 - val_loss: 1062.8131\n",
      "EPOCH 686\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 155.8345 - val_loss: 1055.7660\n",
      "EPOCH 687\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 154.4508 - val_loss: 1058.2946\n",
      "EPOCH 688\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 161.7361 - val_loss: 1059.8687\n",
      "EPOCH 689\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 159.7627 - val_loss: 1055.4408\n",
      "EPOCH 690\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 160.4221 - val_loss: 1050.2113\n",
      "EPOCH 691\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 154.1894 - val_loss: 1061.4265\n",
      "EPOCH 692\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 153.2265 - val_loss: 1049.8918\n",
      "EPOCH 693\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 154.7555 - val_loss: 1053.7443\n",
      "EPOCH 694\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 152.7691 - val_loss: 1050.7130\n",
      "EPOCH 695\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 154.2450 - val_loss: 1052.7822\n",
      "EPOCH 696\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 153.3656 - val_loss: 1056.3347\n",
      "EPOCH 697\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 153.5362 - val_loss: 1055.1278\n",
      "EPOCH 698\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 156.5918 - val_loss: 1057.1942\n",
      "EPOCH 699\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 159.9622 - val_loss: 1058.5890\n",
      "EPOCH 700\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 160.2855 - val_loss: 1047.1482\n",
      "EPOCH 701\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 163.6032 - val_loss: 1066.2786\n",
      "EPOCH 702\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 160.5794 - val_loss: 1057.6858\n",
      "EPOCH 703\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 161.8517 - val_loss: 1056.9210\n",
      "EPOCH 704\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 158.5048 - val_loss: 1054.1899\n",
      "EPOCH 705\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 154.9558 - val_loss: 1058.0488\n",
      "EPOCH 706\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 152.4045 - val_loss: 1047.4268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 707\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 149.7582 - val_loss: 1055.1703\n",
      "EPOCH 708\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 146.3051 - val_loss: 1055.1199\n",
      "EPOCH 709\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 142.5021 - val_loss: 1063.0210\n",
      "EPOCH 710\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 141.2463 - val_loss: 1061.7365\n",
      "EPOCH 711\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 139.1563 - val_loss: 1058.6353\n",
      "EPOCH 712\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 138.5925 - val_loss: 1058.2784\n",
      "EPOCH 713\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 138.1263 - val_loss: 1061.1525\n",
      "EPOCH 714\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 138.3541 - val_loss: 1063.9036\n",
      "EPOCH 715\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 138.5340 - val_loss: 1061.6187\n",
      "EPOCH 716\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 139.7310 - val_loss: 1060.3489\n",
      "EPOCH 717\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 139.5901 - val_loss: 1055.0210\n",
      "EPOCH 718\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 139.8733 - val_loss: 1060.3915\n",
      "EPOCH 719\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 138.5522 - val_loss: 1061.0328\n",
      "EPOCH 720\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 138.0654 - val_loss: 1059.8770\n",
      "EPOCH 721\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 137.4034 - val_loss: 1060.9669\n",
      "EPOCH 722\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 136.3257 - val_loss: 1062.3215\n",
      "EPOCH 723\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 137.4623 - val_loss: 1060.5627\n",
      "EPOCH 724\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 138.4584 - val_loss: 1060.1199\n",
      "EPOCH 725\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 138.5814 - val_loss: 1058.5743\n",
      "EPOCH 726\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 139.6209 - val_loss: 1063.9761\n",
      "EPOCH 727\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 139.8315 - val_loss: 1060.4689\n",
      "EPOCH 728\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 139.3437 - val_loss: 1061.8973\n",
      "EPOCH 729\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 139.5146 - val_loss: 1057.8550\n",
      "EPOCH 730\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 138.8690 - val_loss: 1064.5061\n",
      "EPOCH 731\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 136.3071 - val_loss: 1062.0721\n",
      "EPOCH 732\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 135.2744 - val_loss: 1057.0259\n",
      "EPOCH 733\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 133.5068 - val_loss: 1060.6205\n",
      "EPOCH 734\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 133.5357 - val_loss: 1065.5345\n",
      "EPOCH 735\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 133.6752 - val_loss: 1066.3555\n",
      "EPOCH 736\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 134.0047 - val_loss: 1061.0065\n",
      "EPOCH 737\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 132.7467 - val_loss: 1062.9999\n",
      "EPOCH 738\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 132.0639 - val_loss: 1060.0134\n",
      "EPOCH 739\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 131.7032 - val_loss: 1063.0326\n",
      "EPOCH 740\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 130.7642 - val_loss: 1066.0051\n",
      "EPOCH 741\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 134.2239 - val_loss: 1063.4341\n",
      "EPOCH 742\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 133.4085 - val_loss: 1060.1805\n",
      "EPOCH 743\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 132.7939 - val_loss: 1067.4702\n",
      "EPOCH 744\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 131.9419 - val_loss: 1070.0853\n",
      "EPOCH 745\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 133.1277 - val_loss: 1065.1870\n",
      "EPOCH 746\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 133.1924 - val_loss: 1063.5316\n",
      "EPOCH 747\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 133.1698 - val_loss: 1061.4410\n",
      "EPOCH 748\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 131.5565 - val_loss: 1069.1049\n",
      "EPOCH 749\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 131.4782 - val_loss: 1065.8195\n",
      "EPOCH 750\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 132.0770 - val_loss: 1069.2439\n",
      "EPOCH 751\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 130.3053 - val_loss: 1063.4760\n",
      "EPOCH 752\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 130.0636 - val_loss: 1069.4000\n",
      "EPOCH 753\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 129.0343 - val_loss: 1068.1343\n",
      "EPOCH 754\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 130.5265 - val_loss: 1067.7028\n",
      "EPOCH 755\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 134.7947 - val_loss: 1062.7789\n",
      "EPOCH 756\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 136.1472 - val_loss: 1069.4028\n",
      "EPOCH 757\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 141.0422 - val_loss: 1073.3800\n",
      "EPOCH 758\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 138.7550 - val_loss: 1068.5435\n",
      "EPOCH 759\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 138.6350 - val_loss: 1064.4247\n",
      "EPOCH 760\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 137.3481 - val_loss: 1071.1752\n",
      "EPOCH 761\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 134.7937 - val_loss: 1066.7324\n",
      "EPOCH 762\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 137.6605 - val_loss: 1074.3112\n",
      "EPOCH 763\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 141.3601 - val_loss: 1065.0017\n",
      "EPOCH 764\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 147.1001 - val_loss: 1071.9619\n",
      "EPOCH 765\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 158.3387 - val_loss: 1091.9137\n",
      "EPOCH 766\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 161.8406 - val_loss: 1066.3784\n",
      "EPOCH 767\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 161.0469 - val_loss: 1072.1473\n",
      "EPOCH 768\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 160.2299 - val_loss: 1071.1820\n",
      "EPOCH 769\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 164.0395 - val_loss: 1083.7469\n",
      "EPOCH 770\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 157.4881 - val_loss: 1059.5792\n",
      "EPOCH 771\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 156.0488 - val_loss: 1084.6624\n",
      "EPOCH 772\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 159.7912 - val_loss: 1075.9495\n",
      "EPOCH 773\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 147.0255 - val_loss: 1068.5154\n",
      "EPOCH 774\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 147.4937 - val_loss: 1074.2833\n",
      "EPOCH 775\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 147.9075 - val_loss: 1077.1725\n",
      "EPOCH 776\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 143.8111 - val_loss: 1072.5983\n",
      "EPOCH 777\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 144.3678 - val_loss: 1067.0072\n",
      "EPOCH 778\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 151.2734 - val_loss: 1078.6652\n",
      "EPOCH 779\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 144.2839 - val_loss: 1083.9039\n",
      "EPOCH 780\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 156.1109 - val_loss: 1085.3708\n",
      "EPOCH 781\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 154.8866 - val_loss: 1075.8716\n",
      "EPOCH 782\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 153.0939 - val_loss: 1073.9329\n",
      "EPOCH 783\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 160.0156 - val_loss: 1072.3612\n",
      "EPOCH 784\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 167.0907 - val_loss: 1074.4135\n",
      "EPOCH 785\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 158.5509 - val_loss: 1079.9590\n",
      "EPOCH 786\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 166.3202 - val_loss: 1071.9169\n",
      "EPOCH 787\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 177.2628 - val_loss: 1070.6204\n",
      "EPOCH 788\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 160.3336 - val_loss: 1080.1912\n",
      "EPOCH 789\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 160.9417 - val_loss: 1073.4554\n",
      "EPOCH 790\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 158.9477 - val_loss: 1075.6793\n",
      "EPOCH 791\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 144.2870 - val_loss: 1075.0818\n",
      "EPOCH 792\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 141.5810 - val_loss: 1077.4052\n",
      "EPOCH 793\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 145.0862 - val_loss: 1077.9916\n",
      "EPOCH 794\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 143.2289 - val_loss: 1073.2448\n",
      "EPOCH 795\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 131.8973 - val_loss: 1071.9862\n",
      "EPOCH 796\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 131.1318 - val_loss: 1074.7396\n",
      "EPOCH 797\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 134.2228 - val_loss: 1078.6071\n",
      "EPOCH 798\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 131.2174 - val_loss: 1078.6510\n",
      "EPOCH 799\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 130.5024 - val_loss: 1080.7919\n",
      "EPOCH 800\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 127.5904 - val_loss: 1072.0608\n",
      "EPOCH 801\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 125.4057 - val_loss: 1073.6527\n",
      "EPOCH 802\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 124.1299 - val_loss: 1079.0089\n",
      "EPOCH 803\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 123.9154 - val_loss: 1074.7029\n",
      "EPOCH 804\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 122.7578 - val_loss: 1074.2769\n",
      "EPOCH 805\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 119.9126 - val_loss: 1082.9644\n",
      "EPOCH 806\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 118.2698 - val_loss: 1081.6582\n",
      "EPOCH 807\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 117.6870 - val_loss: 1079.3676\n",
      "EPOCH 808\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 116.9325 - val_loss: 1080.7471\n",
      "EPOCH 809\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 117.1104 - val_loss: 1078.0958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 810\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 116.7125 - val_loss: 1081.8092\n",
      "EPOCH 811\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 117.3720 - val_loss: 1078.6273\n",
      "EPOCH 812\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 118.8575 - val_loss: 1083.3184\n",
      "EPOCH 813\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 120.2473 - val_loss: 1081.2260\n",
      "EPOCH 814\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 119.4528 - val_loss: 1081.7572\n",
      "EPOCH 815\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 120.8441 - val_loss: 1085.1024\n",
      "EPOCH 816\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 122.9999 - val_loss: 1082.4240\n",
      "EPOCH 817\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 125.6078 - val_loss: 1076.8400\n",
      "EPOCH 818\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 135.5882 - val_loss: 1086.2368\n",
      "EPOCH 819\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 140.2982 - val_loss: 1084.9102\n",
      "EPOCH 820\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 142.2303 - val_loss: 1087.6050\n",
      "EPOCH 821\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 146.1179 - val_loss: 1083.0083\n",
      "EPOCH 822\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 142.6741 - val_loss: 1086.0208\n",
      "EPOCH 823\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 152.4918 - val_loss: 1069.2319\n",
      "EPOCH 824\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 147.0257 - val_loss: 1085.4010\n",
      "EPOCH 825\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 161.1132 - val_loss: 1086.7777\n",
      "EPOCH 826\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 151.0174 - val_loss: 1076.6995\n",
      "EPOCH 827\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 152.7325 - val_loss: 1071.7218\n",
      "EPOCH 828\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 148.7380 - val_loss: 1082.9951\n",
      "EPOCH 829\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 155.0083 - val_loss: 1071.2615\n",
      "EPOCH 830\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 161.8845 - val_loss: 1085.4618\n",
      "EPOCH 831\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 164.8548 - val_loss: 1078.5059\n",
      "EPOCH 832\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 162.0016 - val_loss: 1076.2450\n",
      "EPOCH 833\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 162.6187 - val_loss: 1090.6487\n",
      "EPOCH 834\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 166.5993 - val_loss: 1075.6045\n",
      "EPOCH 835\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 183.7625 - val_loss: 1088.1302\n",
      "EPOCH 836\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 180.8669 - val_loss: 1057.0315\n",
      "EPOCH 837\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 173.3651 - val_loss: 1087.9684\n",
      "EPOCH 838\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 164.7871 - val_loss: 1082.8651\n",
      "EPOCH 839\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 152.0012 - val_loss: 1073.6478\n",
      "EPOCH 840\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 138.7933 - val_loss: 1073.6017\n",
      "EPOCH 841\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 132.0011 - val_loss: 1068.4590\n",
      "EPOCH 842\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 129.3393 - val_loss: 1086.4500\n",
      "EPOCH 843\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 129.5844 - val_loss: 1072.9476\n",
      "EPOCH 844\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 129.7283 - val_loss: 1081.5232\n",
      "EPOCH 845\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 127.4546 - val_loss: 1074.5121\n",
      "EPOCH 846\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 125.2971 - val_loss: 1082.2118\n",
      "EPOCH 847\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 125.7365 - val_loss: 1078.6061\n",
      "EPOCH 848\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 128.4615 - val_loss: 1080.7535\n",
      "EPOCH 849\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 132.4476 - val_loss: 1074.2108\n",
      "EPOCH 850\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 132.4000 - val_loss: 1085.7570\n",
      "EPOCH 851\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 144.7668 - val_loss: 1062.3046\n",
      "EPOCH 852\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 146.3821 - val_loss: 1053.3322\n",
      "EPOCH 853\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 149.1354 - val_loss: 1071.1458\n",
      "EPOCH 854\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 140.8961 - val_loss: 1055.3075\n",
      "EPOCH 855\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 141.0239 - val_loss: 1074.2980\n",
      "EPOCH 856\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 141.7891 - val_loss: 1050.6990\n",
      "EPOCH 857\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 146.3029 - val_loss: 1057.5032\n",
      "EPOCH 858\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 138.0095 - val_loss: 1062.0502\n",
      "EPOCH 859\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 134.1445 - val_loss: 1063.1383\n",
      "EPOCH 860\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 132.0704 - val_loss: 1054.5427\n",
      "EPOCH 861\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 131.4238 - val_loss: 1057.2965\n",
      "EPOCH 862\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 125.2091 - val_loss: 1069.7560\n",
      "EPOCH 863\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 123.7929 - val_loss: 1064.5559\n",
      "EPOCH 864\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 120.3986 - val_loss: 1053.6655\n",
      "EPOCH 865\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 120.6726 - val_loss: 1062.3013\n",
      "EPOCH 866\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 121.3616 - val_loss: 1057.9843\n",
      "EPOCH 867\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 119.0234 - val_loss: 1060.8922\n",
      "EPOCH 868\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 115.1580 - val_loss: 1067.1760\n",
      "EPOCH 869\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 113.9999 - val_loss: 1060.4905\n",
      "EPOCH 870\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 115.2664 - val_loss: 1058.4364\n",
      "EPOCH 871\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 113.5343 - val_loss: 1058.1348\n",
      "EPOCH 872\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 113.6057 - val_loss: 1058.6422\n",
      "EPOCH 873\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 117.4145 - val_loss: 1064.8121\n",
      "EPOCH 874\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 120.3010 - val_loss: 1065.5426\n",
      "EPOCH 875\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 120.8033 - val_loss: 1058.4023\n",
      "EPOCH 876\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 121.4427 - val_loss: 1060.9658\n",
      "EPOCH 877\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 120.0105 - val_loss: 1061.0236\n",
      "EPOCH 878\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 120.7716 - val_loss: 1067.9142\n",
      "EPOCH 879\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 116.7724 - val_loss: 1066.7440\n",
      "EPOCH 880\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 115.2648 - val_loss: 1057.9530\n",
      "EPOCH 881\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 115.9401 - val_loss: 1064.4718\n",
      "EPOCH 882\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 114.3485 - val_loss: 1063.7192\n",
      "EPOCH 883\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 111.9539 - val_loss: 1064.7423\n",
      "EPOCH 884\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 109.8675 - val_loss: 1067.9651\n",
      "EPOCH 885\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 108.9489 - val_loss: 1071.9080\n",
      "EPOCH 886\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 111.4181 - val_loss: 1070.5831\n",
      "EPOCH 887\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 109.8621 - val_loss: 1070.3888\n",
      "EPOCH 888\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 108.8233 - val_loss: 1068.6262\n",
      "EPOCH 889\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 108.6408 - val_loss: 1072.0104\n",
      "EPOCH 890\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 113.5583 - val_loss: 1074.6416\n",
      "EPOCH 891\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 112.0011 - val_loss: 1074.2356\n",
      "EPOCH 892\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 109.9011 - val_loss: 1079.2777\n",
      "EPOCH 893\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 110.1641 - val_loss: 1077.5259\n",
      "EPOCH 894\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 111.9702 - val_loss: 1070.6456\n",
      "EPOCH 895\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 110.8694 - val_loss: 1070.8676\n",
      "EPOCH 896\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 110.6095 - val_loss: 1076.3846\n",
      "EPOCH 897\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 115.3228 - val_loss: 1080.6750\n",
      "EPOCH 898\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 112.5236 - val_loss: 1078.1414\n",
      "EPOCH 899\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 111.5865 - val_loss: 1072.1534\n",
      "EPOCH 900\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 112.9205 - val_loss: 1073.4355\n",
      "EPOCH 901\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 119.8037 - val_loss: 1078.7521\n",
      "EPOCH 902\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 114.8084 - val_loss: 1076.8938\n",
      "EPOCH 903\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 116.4556 - val_loss: 1074.1968\n",
      "EPOCH 904\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 116.3640 - val_loss: 1069.2185\n",
      "EPOCH 905\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 120.7974 - val_loss: 1076.5920\n",
      "EPOCH 906\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 118.7274 - val_loss: 1079.1040\n",
      "EPOCH 907\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 114.2952 - val_loss: 1077.6211\n",
      "EPOCH 908\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 117.1774 - val_loss: 1070.4508\n",
      "EPOCH 909\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 119.1734 - val_loss: 1074.2531\n",
      "EPOCH 910\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 117.2387 - val_loss: 1073.1785\n",
      "EPOCH 911\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 117.5112 - val_loss: 1085.7133\n",
      "EPOCH 912\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 118.8281 - val_loss: 1074.7297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 913\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 116.2309 - val_loss: 1080.5535\n",
      "EPOCH 914\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 112.8637 - val_loss: 1078.6591\n",
      "EPOCH 915\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 108.2513 - val_loss: 1082.5264\n",
      "EPOCH 916\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 107.6486 - val_loss: 1073.8495\n",
      "EPOCH 917\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 104.7609 - val_loss: 1077.8673\n",
      "EPOCH 918\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 103.3530 - val_loss: 1076.9043\n",
      "EPOCH 919\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 103.1804 - val_loss: 1081.7780\n",
      "EPOCH 920\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.5963 - val_loss: 1081.9329\n",
      "EPOCH 921\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.1984 - val_loss: 1077.8658\n",
      "EPOCH 922\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.4156 - val_loss: 1077.8711\n",
      "EPOCH 923\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.8415 - val_loss: 1084.1282\n",
      "EPOCH 924\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.0259 - val_loss: 1078.0100\n",
      "EPOCH 925\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.2109 - val_loss: 1084.1521\n",
      "EPOCH 926\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.3086 - val_loss: 1082.7388\n",
      "EPOCH 927\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.0193 - val_loss: 1083.9559\n",
      "EPOCH 928\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.3351 - val_loss: 1083.7927\n",
      "EPOCH 929\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.5385 - val_loss: 1089.6599\n",
      "EPOCH 930\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.6882 - val_loss: 1083.6660\n",
      "EPOCH 931\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.3821 - val_loss: 1085.6107\n",
      "EPOCH 932\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.0394 - val_loss: 1086.8701\n",
      "EPOCH 933\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 99.8836 - val_loss: 1084.4836\n",
      "EPOCH 934\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 99.7844 - val_loss: 1089.9822\n",
      "EPOCH 935\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 99.7842 - val_loss: 1093.1826\n",
      "EPOCH 936\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.1392 - val_loss: 1088.2545\n",
      "EPOCH 937\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.7075 - val_loss: 1087.6539\n",
      "EPOCH 938\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.4503 - val_loss: 1091.2244\n",
      "EPOCH 939\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.3731 - val_loss: 1089.8252\n",
      "EPOCH 940\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.2874 - val_loss: 1094.8455\n",
      "EPOCH 941\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 102.0982 - val_loss: 1092.7830\n",
      "EPOCH 942\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.6367 - val_loss: 1087.4911\n",
      "EPOCH 943\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 99.0716 - val_loss: 1093.2924\n",
      "EPOCH 944\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.1181 - val_loss: 1091.0590\n",
      "EPOCH 945\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.2376 - val_loss: 1087.4025\n",
      "EPOCH 946\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.3037 - val_loss: 1095.9928\n",
      "EPOCH 947\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.2566 - val_loss: 1096.4550\n",
      "EPOCH 948\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.2720 - val_loss: 1094.1447\n",
      "EPOCH 949\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.3726 - val_loss: 1096.5637\n",
      "EPOCH 950\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.5530 - val_loss: 1095.0217\n",
      "EPOCH 951\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.3375 - val_loss: 1089.6650\n",
      "EPOCH 952\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.2016 - val_loss: 1100.2792\n",
      "EPOCH 953\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.3692 - val_loss: 1094.4222\n",
      "EPOCH 954\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 104.6329 - val_loss: 1094.8938\n",
      "EPOCH 955\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.3254 - val_loss: 1095.7054\n",
      "EPOCH 956\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 97.5385 - val_loss: 1096.9760\n",
      "EPOCH 957\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 97.3360 - val_loss: 1090.5518\n",
      "EPOCH 958\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 95.1300 - val_loss: 1097.4170\n",
      "EPOCH 959\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 94.4682 - val_loss: 1096.6803\n",
      "EPOCH 960\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 93.8393 - val_loss: 1091.2633\n",
      "EPOCH 961\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 94.4764 - val_loss: 1097.4131\n",
      "EPOCH 962\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 94.7455 - val_loss: 1100.4960\n",
      "EPOCH 963\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 94.7444 - val_loss: 1099.4730\n",
      "EPOCH 964\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 95.3311 - val_loss: 1095.6879\n",
      "EPOCH 965\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 95.8128 - val_loss: 1098.0332\n",
      "EPOCH 966\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 98.4755 - val_loss: 1097.5717\n",
      "EPOCH 967\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 98.3302 - val_loss: 1101.3118\n",
      "EPOCH 968\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 101.3028 - val_loss: 1091.2302\n",
      "EPOCH 969\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 103.4928 - val_loss: 1093.2219\n",
      "EPOCH 970\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 107.5582 - val_loss: 1090.7301\n",
      "EPOCH 971\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 115.4153 - val_loss: 1091.4674\n",
      "EPOCH 972\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 122.3449 - val_loss: 1093.4178\n",
      "EPOCH 973\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 124.6153 - val_loss: 1093.1914\n",
      "EPOCH 974\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 121.7360 - val_loss: 1085.3180\n",
      "EPOCH 975\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 116.5586 - val_loss: 1093.2483\n",
      "EPOCH 976\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 113.3527 - val_loss: 1088.2461\n",
      "EPOCH 977\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 108.7267 - val_loss: 1085.7448\n",
      "EPOCH 978\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 103.2833 - val_loss: 1096.4022\n",
      "EPOCH 979\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 100.5120 - val_loss: 1086.6409\n",
      "EPOCH 980\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 99.3798 - val_loss: 1095.5750\n",
      "EPOCH 981\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 95.9857 - val_loss: 1099.3595\n",
      "EPOCH 982\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 94.4804 - val_loss: 1097.8917\n",
      "EPOCH 983\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 93.0402 - val_loss: 1089.4365\n",
      "EPOCH 984\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 91.1556 - val_loss: 1093.1006\n",
      "EPOCH 985\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 90.3826 - val_loss: 1100.3199\n",
      "EPOCH 986\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 89.8979 - val_loss: 1096.5242\n",
      "EPOCH 987\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 88.8516 - val_loss: 1092.5280\n",
      "EPOCH 988\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 88.3780 - val_loss: 1094.1864\n",
      "EPOCH 989\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 88.0114 - val_loss: 1098.0356\n",
      "EPOCH 990\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 87.6307 - val_loss: 1098.4524\n",
      "EPOCH 991\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 87.1991 - val_loss: 1098.8644\n",
      "EPOCH 992\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.9104 - val_loss: 1098.0588\n",
      "EPOCH 993\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.6395 - val_loss: 1099.4241\n",
      "EPOCH 994\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.6382 - val_loss: 1100.7544\n",
      "EPOCH 995\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 86.8627 - val_loss: 1100.4086\n",
      "EPOCH 996\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 87.6848 - val_loss: 1101.2256\n",
      "EPOCH 997\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 88.5574 - val_loss: 1101.5996\n",
      "EPOCH 998\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 88.3187 - val_loss: 1098.8954\n",
      "EPOCH 999\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 89.7381 - val_loss: 1101.4912\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TRAIN LOOP\n",
    "for epoch in range(1000):\n",
    "    print('EPOCH %d' % (epoch))\n",
    "    hist = seq.train(X_train=X_train[:, 0:X_train.shape[1]//2, :], \n",
    "                     Y_train=X_train[:, X_train.shape[1]//2:, :], \n",
    "                     X_val=X_val[:, 0:X_val.shape[1]//2, :], \n",
    "                     Y_val=X_val[:, X_train.shape[1]//2:, :], \n",
    "                     epochs=1, \n",
    "                     batch_size=32\n",
    "                     )\n",
    "    history[\"loss\"].append(hist.history[\"loss\"][0])\n",
    "    history[\"val_loss\"].append(hist.history[\"val_loss\"][0])\n",
    "    if epoch % 500 == 0:\n",
    "        i = random.randint(0, X_train.shape[0]-1)\n",
    "        X, Y = [], []\n",
    "        x = X_train[i, 0:X_train.shape[1]//2, :]\n",
    "        X.append(x)\n",
    "        X = np.array(X)\n",
    "        y = X_train[i, X_train.shape[1]//2:, :]\n",
    "        Y.append(y)\n",
    "        Y = np.array(Y)\n",
    "        Y_hat = seq.model.predict(X)\n",
    "        Y_decoded = ae.decode_series(Y)\n",
    "        Y_hat_decoded = ae.decode_series(Y_hat)\n",
    "        compare_images_as_video(Y_decoded[0], Y_hat_decoded[0])\n",
    "    seq.save_weights(root+\"/../models/seq2seq_many_to_many_past_future_32.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

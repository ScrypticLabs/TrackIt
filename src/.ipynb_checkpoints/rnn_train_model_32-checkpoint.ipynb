{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS NOTEBOOK TRAINS THE FIRST RNN LSTM ENCODER-DECODER MODEL ON 32by32 RESOLUTION DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from data_loader import DataLoader\n",
    "from utils.visualize import show_images_in_grid, show_images_as_video, show_reconstructions, compare_images_as_video\n",
    "from cnn import Autoencoder\n",
    "from rnn import Seq2Seq\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_data_loader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_data_loader.X_train = np.load(root+\"/../datasets/train/32/X_train_normalized.npy\")\n",
    "rnn_data_loader.X_val = np.load(root+\"/../datasets/val/32/X_val_normalized.npy\")\n",
    "rnn_data_loader.X_test = np.load(root+\"/../datasets/test/32/X_test_normalized.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 100, 32, 32, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_data_loader.X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LET'S COMPUTE THE EMBEDDINGS FROM THE DATA AND TRAINED AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = Autoencoder()\n",
    "ae.build_model(input_dim=(32, 32, 3), latent_dim=(64,))\n",
    "ae.set_weights(root+\"/../models/autoencoder_32.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ae.encode_series(rnn_data_loader.X_train)\n",
    "X_val = ae.encode_series(rnn_data_loader.X_val)\n",
    "X_test = ae.encode_series(rnn_data_loader.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 100, 64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = Seq2Seq()\n",
    "seq.build_model(input_length=20, input_dim=64, latent_dim=(256,), output_length=30, output_dim=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq.set_weights(root+\"/../models/seq2seq_32.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 20, 1024)          4460544   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 20, 512)           3147776   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 256)               787456    \n",
      "=================================================================\n",
      "Total params: 8,395,776\n",
      "Trainable params: 8,395,776\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 30, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 30, 512)           1574912   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 30, 1024)          6295552   \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 30, 64)            65600     \n",
      "=================================================================\n",
      "Total params: 7,936,064\n",
      "Trainable params: 7,936,064\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    \"loss\" : [],\n",
    "    \"val_loss\" : []\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 501\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 120.0608 - val_loss: 977.4210\n",
      "EPOCH 502\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 118.8362 - val_loss: 977.5115\n",
      "EPOCH 503\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 121.1010 - val_loss: 974.1769\n",
      "EPOCH 504\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 118.8735 - val_loss: 976.0217\n",
      "EPOCH 505\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 120.1131 - val_loss: 975.2125\n",
      "EPOCH 506\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 120.6274 - val_loss: 985.7072\n",
      "EPOCH 507\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 122.0461 - val_loss: 982.5428\n",
      "EPOCH 508\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 122.3266 - val_loss: 986.6951\n",
      "EPOCH 509\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 122.1125 - val_loss: 984.1542\n",
      "EPOCH 510\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 121.3677 - val_loss: 982.2252\n",
      "EPOCH 511\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 124.6853 - val_loss: 983.6490\n",
      "EPOCH 512\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 131.5292 - val_loss: 976.0055\n",
      "EPOCH 513\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 129.7816 - val_loss: 983.8473\n",
      "EPOCH 514\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 128.6976 - val_loss: 971.7375\n",
      "EPOCH 515\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 127.7330 - val_loss: 984.1863\n",
      "EPOCH 516\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 126.5398 - val_loss: 978.0226\n",
      "EPOCH 517\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 126.5799 - val_loss: 978.7479\n",
      "EPOCH 518\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 118.2463 - val_loss: 981.0949\n",
      "EPOCH 519\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 118.5095 - val_loss: 980.2766\n",
      "EPOCH 520\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 120.0372 - val_loss: 976.9862\n",
      "EPOCH 521\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 117.1357 - val_loss: 985.1027\n",
      "EPOCH 522\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 117.7406 - val_loss: 973.6077\n",
      "EPOCH 523\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 115.4150 - val_loss: 980.6720\n",
      "EPOCH 524\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 113.6670 - val_loss: 981.6283\n",
      "EPOCH 525\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 111.0247 - val_loss: 979.3397\n",
      "EPOCH 526\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 109.5349 - val_loss: 983.2316\n",
      "EPOCH 527\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 109.3446 - val_loss: 979.7746\n",
      "EPOCH 528\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 107.0731 - val_loss: 981.5475\n",
      "EPOCH 529\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 106.2352 - val_loss: 984.3416\n",
      "EPOCH 530\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 105.1573 - val_loss: 984.0076\n",
      "EPOCH 531\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 104.6320 - val_loss: 982.6834\n",
      "EPOCH 532\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 104.5952 - val_loss: 985.6768\n",
      "EPOCH 533\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 104.0419 - val_loss: 981.7072\n",
      "EPOCH 534\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 104.1639 - val_loss: 989.6994\n",
      "EPOCH 535\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 104.4905 - val_loss: 988.3794\n",
      "EPOCH 536\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 104.2472 - val_loss: 986.5194\n",
      "EPOCH 537\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 104.2013 - val_loss: 986.7923\n",
      "EPOCH 538\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 105.0632 - val_loss: 989.8134\n",
      "EPOCH 539\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 106.8173 - val_loss: 987.4828\n",
      "EPOCH 540\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 107.7323 - val_loss: 996.0834\n",
      "EPOCH 541\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 107.3197 - val_loss: 992.0685\n",
      "EPOCH 542\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 111.4043 - val_loss: 992.5848\n",
      "EPOCH 543\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 112.5149 - val_loss: 992.5944\n",
      "EPOCH 544\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 111.1980 - val_loss: 995.8610\n",
      "EPOCH 545\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 119.8400 - val_loss: 982.6146\n",
      "EPOCH 546\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 118.9285 - val_loss: 979.5787\n",
      "EPOCH 547\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 118.8513 - val_loss: 982.6530\n",
      "EPOCH 548\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 113.0886 - val_loss: 981.1227\n",
      "EPOCH 549\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 110.6289 - val_loss: 984.0765\n",
      "EPOCH 550\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 107.9720 - val_loss: 983.8429\n",
      "EPOCH 551\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 105.1011 - val_loss: 987.2217\n",
      "EPOCH 552\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 103.4264 - val_loss: 986.9642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 553\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 102.1791 - val_loss: 985.1336\n",
      "EPOCH 554\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 101.9073 - val_loss: 982.7601\n",
      "EPOCH 555\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 100.9294 - val_loss: 993.8954\n",
      "EPOCH 556\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 102.3399 - val_loss: 991.2639\n",
      "EPOCH 557\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 105.1609 - val_loss: 992.7697\n",
      "EPOCH 558\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 104.8745 - val_loss: 991.4197\n",
      "EPOCH 559\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 105.6687 - val_loss: 988.6791\n",
      "EPOCH 560\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 102.4277 - val_loss: 989.9006\n",
      "EPOCH 561\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 103.2212 - val_loss: 984.1061\n",
      "EPOCH 562\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 104.0767 - val_loss: 993.6843\n",
      "EPOCH 563\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 102.6485 - val_loss: 991.8719\n",
      "EPOCH 564\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 100.4177 - val_loss: 996.5148\n",
      "EPOCH 565\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 99.7858 - val_loss: 990.4041\n",
      "EPOCH 566\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 99.0279 - val_loss: 993.6110\n",
      "EPOCH 567\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 98.7325 - val_loss: 990.4045\n",
      "EPOCH 568\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 97.8133 - val_loss: 995.2711\n",
      "EPOCH 569\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 96.3032 - val_loss: 989.9135\n",
      "EPOCH 570\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 95.1294 - val_loss: 994.5543\n",
      "EPOCH 571\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 94.9642 - val_loss: 992.1788\n",
      "EPOCH 572\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 93.8748 - val_loss: 990.0653\n",
      "EPOCH 573\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 93.2606 - val_loss: 991.6998\n",
      "EPOCH 574\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 92.9231 - val_loss: 993.3224\n",
      "EPOCH 575\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 92.4652 - val_loss: 995.3594\n",
      "EPOCH 576\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 92.2165 - val_loss: 994.6068\n",
      "EPOCH 577\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 91.5527 - val_loss: 991.8260\n",
      "EPOCH 578\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 91.0112 - val_loss: 993.4807\n",
      "EPOCH 579\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 90.7671 - val_loss: 994.9982\n",
      "EPOCH 580\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 90.0661 - val_loss: 994.3840\n",
      "EPOCH 581\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 90.4940 - val_loss: 993.4920\n",
      "EPOCH 582\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 90.3244 - val_loss: 994.5361\n",
      "EPOCH 583\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 89.7587 - val_loss: 994.5095\n",
      "EPOCH 584\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 89.7983 - val_loss: 993.4811\n",
      "EPOCH 585\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 89.4897 - val_loss: 994.2345\n",
      "EPOCH 586\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 90.2402 - val_loss: 995.7834\n",
      "EPOCH 587\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 89.6962 - val_loss: 994.4598\n",
      "EPOCH 588\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 90.2330 - val_loss: 996.5344\n",
      "EPOCH 589\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 90.1235 - val_loss: 996.1546\n",
      "EPOCH 590\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 90.6584 - val_loss: 991.4404\n",
      "EPOCH 591\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 92.8127 - val_loss: 996.8695\n",
      "EPOCH 592\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 95.0523 - val_loss: 993.1922\n",
      "EPOCH 593\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 95.2894 - val_loss: 1000.4621\n",
      "EPOCH 594\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 94.6940 - val_loss: 1002.8299\n",
      "EPOCH 595\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 94.7665 - val_loss: 1000.1959\n",
      "EPOCH 596\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 93.0822 - val_loss: 996.7726\n",
      "EPOCH 597\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 93.9371 - val_loss: 996.0547\n",
      "EPOCH 598\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 93.4131 - val_loss: 1001.9655\n",
      "EPOCH 599\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 93.8973 - val_loss: 995.9713\n",
      "EPOCH 600\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 92.9534 - val_loss: 999.2883\n",
      "EPOCH 601\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 91.3902 - val_loss: 1002.9440\n",
      "EPOCH 602\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 90.0445 - val_loss: 1001.4113\n",
      "EPOCH 603\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 89.2187 - val_loss: 1002.5900\n",
      "EPOCH 604\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 88.3395 - val_loss: 1005.9022\n",
      "EPOCH 605\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 89.4762 - val_loss: 1001.1320\n",
      "EPOCH 606\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 89.2741 - val_loss: 1005.5787\n",
      "EPOCH 607\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 92.2893 - val_loss: 1005.9299\n",
      "EPOCH 608\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 95.9018 - val_loss: 1006.0202\n",
      "EPOCH 609\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 97.1454 - val_loss: 1012.3595\n",
      "EPOCH 610\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 98.8832 - val_loss: 1001.0832\n",
      "EPOCH 611\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 95.6940 - val_loss: 1000.8588\n",
      "EPOCH 612\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 95.0870 - val_loss: 1001.3631\n",
      "EPOCH 613\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 94.8482 - val_loss: 1000.3367\n",
      "EPOCH 614\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 95.1194 - val_loss: 1004.2775\n",
      "EPOCH 615\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 93.9058 - val_loss: 1003.4543\n",
      "EPOCH 616\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 93.7923 - val_loss: 1000.6057\n",
      "EPOCH 617\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 90.4155 - val_loss: 1000.8359\n",
      "EPOCH 618\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 89.3203 - val_loss: 1004.4318\n",
      "EPOCH 619\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 86.9411 - val_loss: 1004.8993\n",
      "EPOCH 620\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 85.7644 - val_loss: 1006.5841\n",
      "EPOCH 621\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 84.2866 - val_loss: 1003.1027\n",
      "EPOCH 622\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 83.0242 - val_loss: 1002.8307\n",
      "EPOCH 623\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 81.9278 - val_loss: 1002.7966\n",
      "EPOCH 624\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 81.1353 - val_loss: 1004.6110\n",
      "EPOCH 625\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 80.4902 - val_loss: 1005.2946\n",
      "EPOCH 626\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 79.8229 - val_loss: 1004.5735\n",
      "EPOCH 627\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 79.2899 - val_loss: 1004.9406\n",
      "EPOCH 628\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 78.8954 - val_loss: 1004.5765\n",
      "EPOCH 629\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 78.3694 - val_loss: 1006.1294\n",
      "EPOCH 630\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 78.0436 - val_loss: 1006.0775\n",
      "EPOCH 631\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 77.7985 - val_loss: 1005.7170\n",
      "EPOCH 632\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 77.5645 - val_loss: 1007.2579\n",
      "EPOCH 633\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 77.5635 - val_loss: 1007.4608\n",
      "EPOCH 634\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 77.2543 - val_loss: 1007.7687\n",
      "EPOCH 635\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 77.3975 - val_loss: 1007.6556\n",
      "EPOCH 636\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 77.8377 - val_loss: 1011.2670\n",
      "EPOCH 637\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 78.3024 - val_loss: 1009.6918\n",
      "EPOCH 638\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 77.7808 - val_loss: 1006.6730\n",
      "EPOCH 639\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 77.7894 - val_loss: 1007.9349\n",
      "EPOCH 640\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 78.6388 - val_loss: 1005.3840\n",
      "EPOCH 641\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 78.6859 - val_loss: 1013.1993\n",
      "EPOCH 642\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 78.6734 - val_loss: 1013.3345\n",
      "EPOCH 643\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 78.4620 - val_loss: 1013.8883\n",
      "EPOCH 644\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 78.1794 - val_loss: 1013.1022\n",
      "EPOCH 645\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 77.8475 - val_loss: 1009.0506\n",
      "EPOCH 646\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 77.0689 - val_loss: 1012.7512\n",
      "EPOCH 647\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 76.9120 - val_loss: 1012.3553\n",
      "EPOCH 648\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 76.6726 - val_loss: 1012.2844\n",
      "EPOCH 649\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 77.0977 - val_loss: 1011.6246\n",
      "EPOCH 650\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 77.4041 - val_loss: 1012.6362\n",
      "EPOCH 651\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 76.8457 - val_loss: 1014.3588\n",
      "EPOCH 652\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 76.2153 - val_loss: 1011.4742\n",
      "EPOCH 653\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 76.5311 - val_loss: 1015.8374\n",
      "EPOCH 654\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 75.6695 - val_loss: 1009.5853\n",
      "EPOCH 655\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 76.2864 - val_loss: 1013.1918\n",
      "EPOCH 656\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 77.2196 - val_loss: 1012.2801\n",
      "EPOCH 657\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 77.6595 - val_loss: 1014.1400\n",
      "EPOCH 658\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 78.4477 - val_loss: 1014.2267\n",
      "EPOCH 659\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 78.6401 - val_loss: 1012.3854\n",
      "EPOCH 660\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 81.6074 - val_loss: 1013.5070\n",
      "EPOCH 661\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 80.7193 - val_loss: 1005.7552\n",
      "EPOCH 662\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 81.7984 - val_loss: 1012.2262\n",
      "EPOCH 663\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 80.1485 - val_loss: 1019.4069\n",
      "EPOCH 664\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 81.6649 - val_loss: 1016.6863\n",
      "EPOCH 665\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 83.4757 - val_loss: 1015.9618\n",
      "EPOCH 666\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 85.9067 - val_loss: 1010.8344\n",
      "EPOCH 667\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 82.8995 - val_loss: 1014.4967\n",
      "EPOCH 668\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 86.3655 - val_loss: 1016.0168\n",
      "EPOCH 669\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 87.8127 - val_loss: 1014.0545\n",
      "EPOCH 670\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 85.7119 - val_loss: 1008.0363\n",
      "EPOCH 671\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 82.8747 - val_loss: 1016.1696\n",
      "EPOCH 672\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 80.1667 - val_loss: 1006.9090\n",
      "EPOCH 673\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 81.0452 - val_loss: 1012.5404\n",
      "EPOCH 674\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 80.2660 - val_loss: 1009.1415\n",
      "EPOCH 675\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 81.5076 - val_loss: 1012.4696\n",
      "EPOCH 676\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 80.7981 - val_loss: 1013.5272\n",
      "EPOCH 677\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 84.3085 - val_loss: 1011.7410\n",
      "EPOCH 678\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 87.9119 - val_loss: 1013.0515\n",
      "EPOCH 679\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 84.7648 - val_loss: 1015.1789\n",
      "EPOCH 680\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 84.8727 - val_loss: 1019.2648\n",
      "EPOCH 681\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 82.1898 - val_loss: 1019.4818\n",
      "EPOCH 682\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 79.3154 - val_loss: 1015.2335\n",
      "EPOCH 683\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 77.8737 - val_loss: 1016.2665\n",
      "EPOCH 684\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 75.5593 - val_loss: 1010.8104\n",
      "EPOCH 685\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 73.8409 - val_loss: 1013.6340\n",
      "EPOCH 686\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 72.5698 - val_loss: 1015.8151\n",
      "EPOCH 687\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 72.0256 - val_loss: 1015.7142\n",
      "EPOCH 688\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 72.2191 - val_loss: 1013.6354\n",
      "EPOCH 689\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 71.1539 - val_loss: 1012.9941\n",
      "EPOCH 690\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 70.7795 - val_loss: 1014.0275\n",
      "EPOCH 691\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 70.8263 - val_loss: 1018.9860\n",
      "EPOCH 692\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 72.0890 - val_loss: 1026.3531\n",
      "EPOCH 693\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 72.8931 - val_loss: 1024.3580\n",
      "EPOCH 694\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 74.3607 - val_loss: 1021.5736\n",
      "EPOCH 695\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 74.9576 - val_loss: 1019.9994\n",
      "EPOCH 696\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 77.7482 - val_loss: 1019.4760\n",
      "EPOCH 697\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 81.1881 - val_loss: 1019.3678\n",
      "EPOCH 698\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 78.3735 - val_loss: 1012.6805\n",
      "EPOCH 699\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 77.7201 - val_loss: 1018.1056\n",
      "EPOCH 700\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 75.5974 - val_loss: 1020.9752\n",
      "EPOCH 701\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 73.7129 - val_loss: 1022.7838\n",
      "EPOCH 702\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 72.0347 - val_loss: 1014.4279\n",
      "EPOCH 703\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 71.0095 - val_loss: 1017.0389\n",
      "EPOCH 704\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 70.6071 - val_loss: 1017.6735\n",
      "EPOCH 705\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 71.5323 - val_loss: 1016.8146\n",
      "EPOCH 706\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 71.6258 - val_loss: 1018.8505\n",
      "EPOCH 707\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 71.6065 - val_loss: 1019.3416\n",
      "EPOCH 708\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 71.1456 - val_loss: 1018.8783\n",
      "EPOCH 709\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 71.5015 - val_loss: 1014.1300\n",
      "EPOCH 710\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 70.7321 - val_loss: 1023.2372\n",
      "EPOCH 711\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 72.1434 - val_loss: 1020.5015\n",
      "EPOCH 712\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 72.6414 - val_loss: 1018.4572\n",
      "EPOCH 713\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 71.7844 - val_loss: 1023.2180\n",
      "EPOCH 714\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 70.3938 - val_loss: 1023.1436\n",
      "EPOCH 715\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 70.8866 - val_loss: 1025.6566\n",
      "EPOCH 716\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 70.0041 - val_loss: 1023.1776\n",
      "EPOCH 717\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 68.9060 - val_loss: 1019.7640\n",
      "EPOCH 718\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 67.6731 - val_loss: 1023.2484\n",
      "EPOCH 719\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 68.3797 - val_loss: 1013.1037\n",
      "EPOCH 720\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 68.7361 - val_loss: 1019.2885\n",
      "EPOCH 721\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 66.8924 - val_loss: 1019.7079\n",
      "EPOCH 722\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 67.8584 - val_loss: 1022.0475\n",
      "EPOCH 723\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 67.2354 - val_loss: 1016.0859\n",
      "EPOCH 724\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 66.1405 - val_loss: 1020.2509\n",
      "EPOCH 725\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 67.9029 - val_loss: 1021.9103\n",
      "EPOCH 726\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 66.1671 - val_loss: 1022.5827\n",
      "EPOCH 727\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 67.1966 - val_loss: 1023.2736\n",
      "EPOCH 728\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 66.2310 - val_loss: 1024.7734\n",
      "EPOCH 729\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 66.2436 - val_loss: 1027.8413\n",
      "EPOCH 730\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 65.8094 - val_loss: 1022.8557\n",
      "EPOCH 731\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 65.1963 - val_loss: 1021.8029\n",
      "EPOCH 732\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 65.2011 - val_loss: 1023.6976\n",
      "EPOCH 733\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 65.4243 - val_loss: 1024.4364\n",
      "EPOCH 734\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 65.1766 - val_loss: 1026.4823\n",
      "EPOCH 735\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 65.1972 - val_loss: 1019.3339\n",
      "EPOCH 736\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 66.8361 - val_loss: 1021.5015\n",
      "EPOCH 737\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 70.7789 - val_loss: 1025.6919\n",
      "EPOCH 738\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 73.6133 - val_loss: 1026.6111\n",
      "EPOCH 739\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 78.2164 - val_loss: 1025.6481\n",
      "EPOCH 740\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 84.0315 - val_loss: 1020.4641\n",
      "EPOCH 741\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 80.4646 - val_loss: 1024.1040\n",
      "EPOCH 742\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 76.7737 - val_loss: 1020.7062\n",
      "EPOCH 743\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 72.4873 - val_loss: 1028.3124\n",
      "EPOCH 744\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 70.4125 - val_loss: 1021.0773\n",
      "EPOCH 745\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 68.6469 - val_loss: 1025.6035\n",
      "EPOCH 746\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 66.8958 - val_loss: 1017.2966\n",
      "EPOCH 747\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 65.8804 - val_loss: 1015.9081\n",
      "EPOCH 748\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 65.2382 - val_loss: 1025.1819\n",
      "EPOCH 749\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 65.6698 - val_loss: 1023.5179\n",
      "EPOCH 750\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 66.5441 - val_loss: 1021.9031\n",
      "EPOCH 751\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 66.8869 - val_loss: 1020.2640\n",
      "EPOCH 752\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 70.2820 - val_loss: 1026.5216\n",
      "EPOCH 753\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 76.6299 - val_loss: 1024.0759\n",
      "EPOCH 754\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 77.8982 - val_loss: 1020.4069\n",
      "EPOCH 755\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 77.0613 - val_loss: 1023.5248\n",
      "EPOCH 756\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 77.7242 - val_loss: 1022.6852\n",
      "EPOCH 757\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 74.6411 - val_loss: 1032.0369\n",
      "EPOCH 758\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 72.0827 - val_loss: 1023.2445\n",
      "EPOCH 759\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 71.5685 - val_loss: 1027.4550\n",
      "EPOCH 760\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 70.9968 - val_loss: 1023.1366\n",
      "EPOCH 761\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 68.7253 - val_loss: 1018.2624\n",
      "EPOCH 762\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 69.8204 - val_loss: 1018.1209\n",
      "EPOCH 763\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 73.7299 - val_loss: 1023.2743\n",
      "EPOCH 764\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 70.8859 - val_loss: 1027.3549\n",
      "EPOCH 765\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 70.6898 - val_loss: 1022.7980\n",
      "EPOCH 766\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 69.5246 - val_loss: 1018.8014\n",
      "EPOCH 767\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 66.5225 - val_loss: 1030.4554\n",
      "EPOCH 768\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 64.9549 - val_loss: 1027.0621\n",
      "EPOCH 769\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 64.7758 - val_loss: 1020.8508\n",
      "EPOCH 770\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 64.7975 - val_loss: 1021.8605\n",
      "EPOCH 771\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 64.3843 - val_loss: 1021.4852\n",
      "EPOCH 772\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 65.0650 - val_loss: 1022.3387\n",
      "EPOCH 773\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 63.8039 - val_loss: 1023.3192\n",
      "EPOCH 774\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 61.9204 - val_loss: 1022.6390\n",
      "EPOCH 775\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 61.4941 - val_loss: 1022.4940\n",
      "EPOCH 776\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 60.9862 - val_loss: 1022.4606\n",
      "EPOCH 777\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 60.9389 - val_loss: 1024.1495\n",
      "EPOCH 778\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 60.2720 - val_loss: 1020.6860\n",
      "EPOCH 779\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 58.9170 - val_loss: 1020.2001\n",
      "EPOCH 780\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 57.8586 - val_loss: 1023.7086\n",
      "EPOCH 781\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 58.8077 - val_loss: 1021.8981\n",
      "EPOCH 782\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 59.0096 - val_loss: 1024.6963\n",
      "EPOCH 783\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 59.6567 - val_loss: 1024.1090\n",
      "EPOCH 784\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 60.8650 - val_loss: 1022.5436\n",
      "EPOCH 785\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 60.2344 - val_loss: 1027.2332\n",
      "EPOCH 786\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 59.7815 - val_loss: 1022.7377\n",
      "EPOCH 787\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 59.5273 - val_loss: 1027.9492\n",
      "EPOCH 788\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 59.6729 - val_loss: 1021.5060\n",
      "EPOCH 789\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 59.1169 - val_loss: 1023.1791\n",
      "EPOCH 790\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 59.3240 - val_loss: 1026.7773\n",
      "EPOCH 791\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 59.0158 - val_loss: 1027.4658\n",
      "EPOCH 792\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 57.6870 - val_loss: 1027.3995\n",
      "EPOCH 793\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 57.4340 - val_loss: 1025.0344\n",
      "EPOCH 794\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 57.9794 - val_loss: 1031.3253\n",
      "EPOCH 795\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 58.8936 - val_loss: 1028.0437\n",
      "EPOCH 796\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 58.4284 - val_loss: 1028.3905\n",
      "EPOCH 797\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 56.8105 - val_loss: 1025.8674\n",
      "EPOCH 798\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 57.3719 - val_loss: 1026.0605\n",
      "EPOCH 799\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 57.4499 - val_loss: 1027.3774\n",
      "EPOCH 800\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 57.3884 - val_loss: 1026.8314\n",
      "EPOCH 801\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 56.8044 - val_loss: 1025.7504\n",
      "EPOCH 802\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 56.5688 - val_loss: 1025.5465\n",
      "EPOCH 803\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 56.6151 - val_loss: 1024.9764\n",
      "EPOCH 804\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 57.9937 - val_loss: 1029.8502\n",
      "EPOCH 805\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 59.7765 - val_loss: 1030.7064\n",
      "EPOCH 806\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 64.6210 - val_loss: 1023.6108\n",
      "EPOCH 807\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 65.8382 - val_loss: 1032.7249\n",
      "EPOCH 808\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 62.6624 - val_loss: 1029.8521\n",
      "EPOCH 809\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 62.9709 - val_loss: 1030.0526\n",
      "EPOCH 810\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 66.7481 - val_loss: 1026.6664\n",
      "EPOCH 811\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 71.1941 - val_loss: 1026.8712\n",
      "EPOCH 812\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 75.1689 - val_loss: 1035.2245\n",
      "EPOCH 813\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 78.4547 - val_loss: 1042.8827\n",
      "EPOCH 814\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 77.0090 - val_loss: 1043.1962\n",
      "EPOCH 815\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 79.4672 - val_loss: 1020.5812\n",
      "EPOCH 816\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 81.0598 - val_loss: 1031.3110\n",
      "EPOCH 817\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 76.0734 - val_loss: 1030.9702\n",
      "EPOCH 818\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 71.4220 - val_loss: 1036.5763\n",
      "EPOCH 819\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 68.6149 - val_loss: 1038.0903\n",
      "EPOCH 820\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 70.8273 - val_loss: 1031.3876\n",
      "EPOCH 821\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 64.9578 - val_loss: 1026.4321\n",
      "EPOCH 822\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 62.4263 - val_loss: 1029.6019\n",
      "EPOCH 823\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 59.5995 - val_loss: 1033.5631\n",
      "EPOCH 824\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 58.9545 - val_loss: 1036.2537\n",
      "EPOCH 825\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 58.2920 - val_loss: 1033.9023\n",
      "EPOCH 826\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 55.4834 - val_loss: 1034.1808\n",
      "EPOCH 827\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 55.7969 - val_loss: 1037.6500\n",
      "EPOCH 828\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 56.4531 - val_loss: 1034.7810\n",
      "EPOCH 829\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 55.7571 - val_loss: 1031.4694\n",
      "EPOCH 830\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 55.8746 - val_loss: 1033.2766\n",
      "EPOCH 831\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 55.1368 - val_loss: 1038.9076\n",
      "EPOCH 832\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 54.7962 - val_loss: 1037.1675\n",
      "EPOCH 833\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 55.3514 - val_loss: 1034.4238\n",
      "EPOCH 834\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 57.5373 - val_loss: 1031.9207\n",
      "EPOCH 835\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 59.1992 - val_loss: 1034.9209\n",
      "EPOCH 836\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 59.6383 - val_loss: 1036.3757\n",
      "EPOCH 837\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 62.6268 - val_loss: 1039.6196\n",
      "EPOCH 838\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 61.7612 - val_loss: 1043.4442\n",
      "EPOCH 839\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 62.0806 - val_loss: 1039.8218\n",
      "EPOCH 840\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 62.4710 - val_loss: 1031.0969\n",
      "EPOCH 841\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 60.8913 - val_loss: 1041.8876\n",
      "EPOCH 842\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 60.7348 - val_loss: 1037.7332\n",
      "EPOCH 843\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 58.1106 - val_loss: 1032.5565\n",
      "EPOCH 844\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 58.2080 - val_loss: 1034.1200\n",
      "EPOCH 845\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 57.9764 - val_loss: 1040.7333\n",
      "EPOCH 846\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 57.3051 - val_loss: 1038.3230\n",
      "EPOCH 847\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 57.1636 - val_loss: 1033.4399\n",
      "EPOCH 848\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 58.6156 - val_loss: 1029.9089\n",
      "EPOCH 849\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 59.2690 - val_loss: 1035.0927\n",
      "EPOCH 850\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 59.8279 - val_loss: 1039.3438\n",
      "EPOCH 851\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 59.1563 - val_loss: 1037.8387\n",
      "EPOCH 852\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 57.8462 - val_loss: 1039.0945\n",
      "EPOCH 853\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 56.1514 - val_loss: 1032.1401\n",
      "EPOCH 854\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 55.1443 - val_loss: 1039.2168\n",
      "EPOCH 855\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 53.8139 - val_loss: 1030.5903\n",
      "EPOCH 856\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 52.8549 - val_loss: 1036.7517\n",
      "EPOCH 857\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 52.0000 - val_loss: 1034.8835\n",
      "EPOCH 858\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 51.4994 - val_loss: 1038.7566\n",
      "EPOCH 859\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 51.3229 - val_loss: 1032.9379\n",
      "EPOCH 860\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 51.1515 - val_loss: 1039.0745\n",
      "EPOCH 861\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 50.0419 - val_loss: 1035.3638\n",
      "EPOCH 862\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 50.2883 - val_loss: 1035.1750\n",
      "EPOCH 863\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 50.5691 - val_loss: 1032.7561\n",
      "EPOCH 864\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 51.1282 - val_loss: 1035.1821\n",
      "EPOCH 865\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 52.7404 - val_loss: 1042.0966\n",
      "EPOCH 866\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 53.9690 - val_loss: 1040.4441\n",
      "EPOCH 867\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 53.3547 - val_loss: 1035.9955\n",
      "EPOCH 868\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 53.4058 - val_loss: 1039.7794\n",
      "EPOCH 869\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 51.9428 - val_loss: 1035.0083\n",
      "EPOCH 870\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 52.8136 - val_loss: 1040.2147\n",
      "EPOCH 871\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 52.2554 - val_loss: 1039.5057\n",
      "EPOCH 872\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 51.1956 - val_loss: 1034.3995\n",
      "EPOCH 873\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 50.6038 - val_loss: 1034.6785\n",
      "EPOCH 874\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 50.0871 - val_loss: 1038.2125\n",
      "EPOCH 875\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 49.9560 - val_loss: 1037.9249\n",
      "EPOCH 876\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 51.5313 - val_loss: 1038.5349\n",
      "EPOCH 877\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 54.6875 - val_loss: 1036.2946\n",
      "EPOCH 878\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 56.1557 - val_loss: 1041.5195\n",
      "EPOCH 879\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 58.9927 - val_loss: 1038.7716\n",
      "EPOCH 880\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 57.6678 - val_loss: 1034.0841\n",
      "EPOCH 881\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 55.4849 - val_loss: 1040.6421\n",
      "EPOCH 882\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 53.8287 - val_loss: 1041.4685\n",
      "EPOCH 883\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 50.9705 - val_loss: 1043.9393\n",
      "EPOCH 884\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 49.8084 - val_loss: 1041.5153\n",
      "EPOCH 885\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 48.3936 - val_loss: 1038.4578\n",
      "EPOCH 886\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 47.2841 - val_loss: 1041.4763\n",
      "EPOCH 887\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 46.5411 - val_loss: 1038.6166\n",
      "EPOCH 888\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 46.2041 - val_loss: 1040.9897\n",
      "EPOCH 889\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 45.9166 - val_loss: 1038.3910\n",
      "EPOCH 890\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 45.7646 - val_loss: 1039.9856\n",
      "EPOCH 891\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 45.3295 - val_loss: 1044.2161\n",
      "EPOCH 892\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 44.7914 - val_loss: 1043.4153\n",
      "EPOCH 893\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 44.5113 - val_loss: 1043.0023\n",
      "EPOCH 894\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 44.1696 - val_loss: 1043.7091\n",
      "EPOCH 895\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 44.0164 - val_loss: 1043.4003\n",
      "EPOCH 896\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 43.8829 - val_loss: 1045.5190\n",
      "EPOCH 897\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 43.8738 - val_loss: 1043.7775\n",
      "EPOCH 898\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 43.7604 - val_loss: 1045.8969\n",
      "EPOCH 899\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 43.6163 - val_loss: 1045.8007\n",
      "EPOCH 900\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 43.4536 - val_loss: 1044.8140\n",
      "EPOCH 901\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 43.4703 - val_loss: 1043.7225\n",
      "EPOCH 902\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 43.4704 - val_loss: 1045.9945\n",
      "EPOCH 903\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 43.4356 - val_loss: 1044.9237\n",
      "EPOCH 904\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 43.3777 - val_loss: 1046.5006\n",
      "EPOCH 905\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 43.5541 - val_loss: 1045.9044\n",
      "EPOCH 906\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 43.6893 - val_loss: 1046.7704\n",
      "EPOCH 907\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 43.8826 - val_loss: 1042.8073\n",
      "EPOCH 908\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 43.9854 - val_loss: 1047.2520\n",
      "EPOCH 909\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 44.3171 - val_loss: 1042.5822\n",
      "EPOCH 910\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 45.1351 - val_loss: 1047.5231\n",
      "EPOCH 911\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 45.7580 - val_loss: 1045.2125\n",
      "EPOCH 912\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 46.8171 - val_loss: 1045.9371\n",
      "EPOCH 913\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 46.4946 - val_loss: 1044.8258\n",
      "EPOCH 914\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 47.2742 - val_loss: 1053.6896\n",
      "EPOCH 915\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 46.9537 - val_loss: 1045.7563\n",
      "EPOCH 916\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 47.3063 - val_loss: 1050.9404\n",
      "EPOCH 917\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 47.7205 - val_loss: 1049.8578\n",
      "EPOCH 918\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 47.3536 - val_loss: 1048.8892\n",
      "EPOCH 919\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 50.2128 - val_loss: 1046.1501\n",
      "EPOCH 920\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 51.3931 - val_loss: 1049.2594\n",
      "EPOCH 921\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 54.1262 - val_loss: 1045.1200\n",
      "EPOCH 922\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 52.4111 - val_loss: 1050.3335\n",
      "EPOCH 923\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 51.0772 - val_loss: 1049.1188\n",
      "EPOCH 924\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 51.0006 - val_loss: 1050.4933\n",
      "EPOCH 925\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 50.9256 - val_loss: 1053.2352\n",
      "EPOCH 926\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 50.9627 - val_loss: 1045.5398\n",
      "EPOCH 927\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 50.9794 - val_loss: 1046.2638\n",
      "EPOCH 928\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 50.4243 - val_loss: 1047.6498\n",
      "EPOCH 929\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 50.1087 - val_loss: 1043.5350\n",
      "EPOCH 930\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 49.7262 - val_loss: 1040.2429\n",
      "EPOCH 931\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 49.2850 - val_loss: 1050.7524\n",
      "EPOCH 932\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 49.9457 - val_loss: 1047.5680\n",
      "EPOCH 933\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 49.8566 - val_loss: 1045.7296\n",
      "EPOCH 934\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 48.9637 - val_loss: 1041.6268\n",
      "EPOCH 935\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 51.5375 - val_loss: 1043.4773\n",
      "EPOCH 936\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 53.2554 - val_loss: 1039.2007\n",
      "EPOCH 937\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 53.0101 - val_loss: 1042.6113\n",
      "EPOCH 938\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 51.5304 - val_loss: 1038.4528\n",
      "EPOCH 939\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 49.2791 - val_loss: 1044.7084\n",
      "EPOCH 940\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 47.8623 - val_loss: 1047.1647\n",
      "EPOCH 941\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 47.8676 - val_loss: 1047.6532\n",
      "EPOCH 942\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 46.5211 - val_loss: 1039.3621\n",
      "EPOCH 943\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 45.8203 - val_loss: 1045.2815\n",
      "EPOCH 944\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 45.4292 - val_loss: 1049.3861\n",
      "EPOCH 945\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 45.3686 - val_loss: 1049.3414\n",
      "EPOCH 946\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 47.3532 - val_loss: 1047.4329\n",
      "EPOCH 947\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 48.2581 - val_loss: 1034.5521\n",
      "EPOCH 948\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 47.0594 - val_loss: 1043.1630\n",
      "EPOCH 949\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 47.6384 - val_loss: 1039.2673\n",
      "EPOCH 950\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 47.6802 - val_loss: 1049.7484\n",
      "EPOCH 951\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 47.2934 - val_loss: 1046.8464\n",
      "EPOCH 952\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 48.2981 - val_loss: 1048.2965\n",
      "EPOCH 953\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 48.5565 - val_loss: 1042.8633\n",
      "EPOCH 954\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 47.1576 - val_loss: 1048.2681\n",
      "EPOCH 955\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 46.7258 - val_loss: 1047.4006\n",
      "EPOCH 956\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 45.8720 - val_loss: 1045.2645\n",
      "EPOCH 957\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 45.2619 - val_loss: 1042.7549\n",
      "EPOCH 958\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 45.8764 - val_loss: 1047.7085\n",
      "EPOCH 959\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 45.7603 - val_loss: 1045.9468\n",
      "EPOCH 960\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 44.6565 - val_loss: 1051.0627\n",
      "EPOCH 961\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 43.3348 - val_loss: 1050.3289\n",
      "EPOCH 962\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 44.1474 - val_loss: 1045.4596\n",
      "EPOCH 963\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 45.7638 - val_loss: 1043.5896\n",
      "EPOCH 964\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 44.3900 - val_loss: 1042.0743\n",
      "EPOCH 965\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 43.3801 - val_loss: 1039.9023\n",
      "EPOCH 966\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 42.7562 - val_loss: 1046.9476\n",
      "EPOCH 967\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 42.4515 - val_loss: 1048.7369\n",
      "EPOCH 968\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 42.1611 - val_loss: 1048.0172\n",
      "EPOCH 969\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 41.8133 - val_loss: 1051.2268\n",
      "EPOCH 970\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 44.0267 - val_loss: 1045.2937\n",
      "EPOCH 971\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 44.9944 - val_loss: 1047.7198\n",
      "EPOCH 972\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 45.1224 - val_loss: 1037.8170\n",
      "EPOCH 973\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 46.6336 - val_loss: 1044.1998\n",
      "EPOCH 974\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 48.5702 - val_loss: 1042.8789\n",
      "EPOCH 975\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 44.4627 - val_loss: 1045.2241\n",
      "EPOCH 976\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 42.2849 - val_loss: 1050.6799\n",
      "EPOCH 977\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 41.1052 - val_loss: 1045.3677\n",
      "EPOCH 978\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 40.4138 - val_loss: 1041.0463\n",
      "EPOCH 979\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 40.7738 - val_loss: 1048.7950\n",
      "EPOCH 980\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 40.2910 - val_loss: 1048.7980\n",
      "EPOCH 981\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 39.5171 - val_loss: 1049.4198\n",
      "EPOCH 982\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 39.4593 - val_loss: 1049.0579\n",
      "EPOCH 983\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 39.3539 - val_loss: 1048.7295\n",
      "EPOCH 984\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 38.9947 - val_loss: 1047.3246\n",
      "EPOCH 985\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 39.4850 - val_loss: 1046.0498\n",
      "EPOCH 986\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 39.8213 - val_loss: 1048.0771\n",
      "EPOCH 987\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 41.6444 - val_loss: 1051.7482\n",
      "EPOCH 988\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 43.6909 - val_loss: 1053.3845\n",
      "EPOCH 989\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 44.3246 - val_loss: 1055.3036\n",
      "EPOCH 990\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 44.4410 - val_loss: 1043.3335\n",
      "EPOCH 991\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 46.6111 - val_loss: 1050.0110\n",
      "EPOCH 992\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 48.3123 - val_loss: 1056.3807\n",
      "EPOCH 993\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 46.8239 - val_loss: 1053.4994\n",
      "EPOCH 994\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 48.6635 - val_loss: 1044.8451\n",
      "EPOCH 995\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 48.5495 - val_loss: 1052.7793\n",
      "EPOCH 996\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 48.0130 - val_loss: 1049.0225\n",
      "EPOCH 997\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 51.7451 - val_loss: 1056.7629\n",
      "EPOCH 998\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 53.4409 - val_loss: 1058.4280\n",
      "EPOCH 999\n",
      "Train on 160 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 51.6887 - val_loss: 1050.9033\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TRAIN LOOP\n",
    "for epoch in range(1000):\n",
    "    print('EPOCH %d' % (epoch))\n",
    "    hist =  seq.train(X_train=X_train[:, :20, :], \n",
    "                         Y_train=X_train[:, 20:50, :], \n",
    "                         X_val=X_val[:, :20, :], \n",
    "                         Y_val=X_val[:, 20:50, :], \n",
    "                         epochs=1, \n",
    "                         batch_size=32\n",
    "                         )\n",
    "    history[\"loss\"].append(hist.history[\"loss\"][0])\n",
    "    history[\"val_loss\"].append(hist.history[\"val_loss\"][0])\n",
    "    if epoch % 500 == 0:\n",
    "        i = random.randint(0, X_train.shape[0]-1)\n",
    "        X, Y = [], []\n",
    "        x = X_train[i, :20, :]\n",
    "        X.append(x)\n",
    "        X = np.array(X)\n",
    "        y = X_train[i, 20:50, :]\n",
    "        Y.append(y)\n",
    "        Y = np.array(Y)\n",
    "        Y_hat = seq.model.predict(X)\n",
    "        result = np.concatenate((X, Y_hat), axis=1)\n",
    "        Y_hat_decoded = ae.decode_series(result)\n",
    "        show_images_as_video(Y_hat_decoded[0])\n",
    "    seq.save_weights(root+\"/../models/seq2seq_32.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-a3e053b816ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot training & validation loss values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_videos(train=True, val=False, test=False):\n",
    "    i = 0\n",
    "    if train:\n",
    "        i = random.randint(0, X_train.shape[0]-1)\n",
    "    elif val:\n",
    "        i = random.randint(0, X_val.shape[0]-1)\n",
    "    elif test:\n",
    "        i = random.randint(0, X_test.shape[0]-1)\n",
    "    X, Y = [], []\n",
    "    x, y = None, None\n",
    "    if train:\n",
    "        x = X_train[i, :20, :]\n",
    "        y = X_train[i, 20:50, :]\n",
    "    elif val:\n",
    "        x = X_val[i, :20, :]\n",
    "        y = X_val[i, 20:50, :]\n",
    "    elif test:\n",
    "        x = X_test[i, :20, :]\n",
    "        y = X_test[i, 20:50, :]\n",
    "    X.append(x)\n",
    "    X = np.array(X)\n",
    "    Y.append(y)\n",
    "    Y = np.array(Y)\n",
    "    Y_hat = seq.model.predict(X)\n",
    "    result = np.concatenate((X, Y_hat), axis=1)\n",
    "    Y_hat_decoded = ae.decode_series(result)\n",
    "    result = np.concatenate((X, Y), axis=1)\n",
    "    Y_decoded = ae.decode_series(result)\n",
    "    return Y_decoded[0], Y_hat_decoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y, Y_hat = produce_videos(test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_images_as_video(Y, Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y, Y_hat = produce_videos(test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_images_as_video(Y, Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_long_videos(train=True, val=False, test=False):\n",
    "    i = 0\n",
    "    if train:\n",
    "        i = random.randint(0, X_train.shape[0]-1)\n",
    "    elif val:\n",
    "        i = random.randint(0, X_val.shape[0]-1)\n",
    "    elif test:\n",
    "        i = random.randint(0, X_test.shape[0]-1)\n",
    "    X, Y = [], []\n",
    "    x, y = None, None\n",
    "    if train:\n",
    "        x = X_train[i, :20, :]\n",
    "        y = X_train[i, 20:50, :]\n",
    "    elif val:\n",
    "        x = X_val[i, :20, :]\n",
    "        y = X_val[i, 20:50, :]\n",
    "    elif test:\n",
    "        x = X_test[i, :20, :]\n",
    "        y = X_test[i, 20:50, :]\n",
    "    X.append(x)\n",
    "    X = np.array(X)\n",
    "    Y_hat = seq.model.predict(X)\n",
    "    result = np.concatenate((X, Y_hat), axis=1)\n",
    "    for j in range(1):\n",
    "        X_in = result[:, -20:, :]\n",
    "        Y_hat_out = seq.model.predict(X_in)\n",
    "        result = np.concatenate((result, Y_hat_out), axis=1)    \n",
    "    print(result.shape)\n",
    "    Y_hat_decoded = ae.decode_series(result)\n",
    "    if train:\n",
    "        y = X_train[i, :result.shape[1], :]\n",
    "    elif val:\n",
    "        y = X_val[i, :result.shape[1], :]\n",
    "    elif test:\n",
    "        y = X_test[i, :result.shape[1], :]\n",
    "    Y.append(y)\n",
    "    Y = np.array(Y)    \n",
    "    Y_decoded = ae.decode_series(Y)\n",
    "    return Y_decoded[0], Y_hat_decoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 80, 64)\n"
     ]
    }
   ],
   "source": [
    "Y_long, Y_hat_long = produce_long_videos(test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_images_as_video(Y_long, Y_hat_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
